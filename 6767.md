# 机器学习课程设计项目报告

---

## 1. 项目基本信息

- 小组编号：6767
- 课题名称：多模态房源表示——结构化特征 + 文本标题/设施描述
- 选定城市及范围：London
- 选定时间范围：使用 Listings 数据集中 ttm_ (Trailing Twelve Months) 相关字段，覆盖过去 12 个月的表现。
- 所用数据表：Listings
- 项目 Github 仓库地址：https://github.com/ZJUT-CS/ml-course-project-2025-6767.git

### 1.1 小组成员与角色分工
| 成员   | 姓名   | 学号         | GitHub 用户名 | 主要负责内容（简要）                   |
| ------ | ------ | ------------ | ------------- | -------------------------------------- |
| 学生 1 | 马云翔 | 302023562063 | jzhbmyx       | XGBoost 建模、调参、特征工程、报告撰写 |
| 学生 2 | 徐宏思 | 302023562020 | HS-X-011      | XGBoost 建模、调参、可视化、报告撰写   |
| 学生 3 | 柯嘉澄 | 302023562067 | Geek6666666   | MLP 建模、对比实验、代码整合、报告撰写 |
| 学生 4 | 周子力 | 302023562030 | moore107      | 数据清洗、数据整合、报告撰写           |

---

## 2. 问题背景与数据集说明

### 2.1 业务背景与研究问题

业务背景：Airbnb 共享住宿市场的竞争日益激烈，对于运营方和投资者而言，通过数据驱动的方式识别“现金牛”资产至关重要。本项目聚焦于 London 市场，旨在利用机器学习技术挖掘决定房源收益能力的关键因子。

核心问题：我们将研究问题定义为“优质房源识别”，这是一个典型的二分类预测任务。

目标变量：目标变量为二值标签 high_revpar。基于房源过去 12 个月的每间可售房收入（ttm_revpar），我们将排名前 25% 的房源定义为“高收益房源”（Label=1），其余定义为普通房源（Label=0）。

研究价值：该模型可辅助房东制定定价策略（如清洁费设置），指导软装优化（基于设施词频分析），并为投资选址提供量化参考。
### 2.2 数据来源与筛选规则

数据来源：本项目使用 AirROI Data Portal 提供的 Airbnb 房源数据。

数据表与作用：使用 Listings Data。该表涵盖了房源的物理属性（如卧室数）、运营规则（如清洁费、最小入住晚数）、口碑评分以及文本描述信息，是构建预测模型的核心数据源。

样本量与筛选条件：

样本概况：原始数据集包含 300 条伦敦房源记录，清洗后保留 300 条有效样本用于建模。

筛选与清洗规则：

1.防止信息泄露：严格剔除了 ttm_revenue、ttm_occupancy、l90d_revenue 等 27 个直接包含未来收益信息的字段，仅保留 ttm_revpar 用于构建标签，随后将其从特征集中移除。

2.异常值处理：对 min_nights、photos_count、num_reviews 等数值特征执行了 1% - 99% 分位数的盖帽处理（Clipping），以减少极端长租或异常数据对模型的干扰。

3.缺失值处理：针对 guests、bedrooms 等关键物理属性字段进行了非空校验与填补。

核心特征说明：

![alt text](image-3.png)
![alt text](image-4.png)

基于 EDA 代码分析结果，本项目选取了以下 12 个关键特征进行重点分析与建模：

1.运营成本特征：cleaning_fee（清洁费）— EDA 显示其与 RevPAR 存在潜在关联，反映了定价策略的一部分。

2.物理属性：bedrooms（卧室数）、baths（卫生间数）、guests（容纳人数）— 决定房源的基础溢价能力。

3.房源类型：room_type（房间类型）、listing_type（房源细分类型）— 区分整套房与独立房间的市场表现。

4.运营门槛：min_nights（最小入住天数）— 筛选长租与短租策略。

5.信誉背书：superhost（超赞房东）、professional_management（专业管理）— 反映运营专业度。

6.非结构化文本：listing_name（标题）、amenities（设施）— 通过词云与词频分析（如 wifi, kitchen, garden 等高频词）提取文本特征。

### 2.3 预期目标与分析思路

预期输出：

1.预测模型：构建并对比 MLP 与 XGBoost 模型，预测房源是否属于“高收益”类别。

2.多模态融合：评估引入文本特征（如通过 TF-IDF 提取的标题与设施关键词）对模型性能的提升作用。

3.特征重要性：输出 Feature Importance 排序与 SHAP 分析，识别影响收益的核心驱动力（如：清洁费设置是否关键？哪些设施最能提升溢价？）。

分析思路：遵循“EDA 探索 --> 特征工程 --> 建模评估”的技术路径。首先通过相关性热力图与箱线图验证特征有效性（如清洁费与 RevPAR 的关系），利用词云挖掘高频设施；随后构建结构化特征与文本向量的融合数据集；最后基于 AUC、F1-Score 和 Accuracy 指标优选模型，并输出“优质房源画像”。

## 3. 方法与模型设计

### 3.1 数据预处理与特征工程

本项目采用了一个标准化的数据处理流水线，涵盖数据清洗、结构化特征预处理以及非结构化文本特征提取。

缺失值与异常值处理：

 异常值截断：针对 min_nights (最小入住天数)、num_reviews (评论数)、photos_count (照片数) 等长尾分布严重的数值型特征，采用了 1% - 99% 分位数盖帽法 (Clipping)，将极端值限制在合理区间内，以减少离群点对模型的干扰。

缺失值填补：

 数值型特征：采用中位数进行填补，以保持数据分布的鲁棒性。

 类别型特征：采用众数进行填补。

特征工程与编码：

 连续变量：使用 StandardScaler 进行标准化处理，消除不同量纲带来的影响。

 类别变量：使用 One-Hot Encoding 将 listing_type 和 room_type 等名义变量转化为稀疏向量，并设置 handle_unknown='ignore' 以处理测试集中可能出现的未见类别。

文本特征提取（多模态融合）：

 我们将房源标题与设施描述 拼接为单一文本字段text_combined。

 TF-IDF 向量化：提取 Top 1000 个高频词汇的 TF-IDF 特征，以此捕捉关键词的显式信号。

 BERT 语义嵌入：使用预训练模型 all-MiniLM-L6-v2 将文本转化为 384 维的稠密向量，以捕捉上下文语义信息。
### 3.2 模型选择与设计

为了全面评估不同算法在异构数据（结构化+文本）上的表现，本项目设计并对比了以下两类模型：

`梯度提升树`

 选择原因：XGBoost 在处理表格数据方面表现卓越，能够自动处理特征间的非线性交互，且对特征缩放不敏感。它内置的正则化项能有效防止过拟合，适合本项目样本量较小（约 300 条）的场景。

 适用性：利用其 scale_pos_weight 参数可以轻松处理本项目中存在的类别不平衡问题（正负样本比例约为 1:3）。此外，XGBoost 提供的特征重要性输出对于解释业务驱动力至关重要。

`多层感知机`

 选择原因：作为神经网络的基线，MLP 擅长处理高维稠密特征。

 适用性：引入 BERT 文本嵌入（384维）后，特征空间变得高维且稠密，MLP 能够通过非线性激活函数更好地从这些 Embedding 中提取隐含的语义模式，作为与树模型的对比补充。
### 3.3 超参数设置与训练细节

为了平衡模型的拟合能力与泛化能力，我们对两个核心模型进行了精细的超参数设置。所有实验均在 random_state=42 的设置下进行，以确保结果的可复现性。

`XGBoost Classifier`参数配置

树结构参数：

 n_estimators=300：构建 300 棵树，以确保有足够的迭代次数来拟合复杂模式。

 max_depth=6：限制树的最大深度为 6，防止模型捕捉到过多的噪声（过拟合）。

 learning_rate=0.05：较小的学习率配合较多的树，有助于寻找更优的全局最小值。
采样与正则化（防止过拟合）：

 subsample=0.8 & colsample_bytree=0.8：每棵树仅使用 80% 的样本和特征进行训练，增加随机性以提升泛化能力。

 min_child_weight=1：叶子节点最小权重和，用于控制树的生长。

 gamma=0.1：节点分裂所需的最小损失函数下降值，进一步限制树的生长。

 reg_alpha=0.1 (L1) & reg_lambda=2 (L2)：混合使用 L1 和 L2 正则化项，降低模型复杂度。
样本不平衡处理：

 scale_pos_weight=3：针对正样本（Top 25%）较少的情况，赋予正样本约 3 倍的权重，显著提升模型对“高收益房源”的召回能力。

`MLP Classifier`参数配置

网络结构：

 hidden_layer_sizes=(128, 64)：采用双隐层结构，第一层 128 个神经元，第二层 64 个神经元，逐步压缩特征空间以提取高阶语义。

 activation='relu'：使用 ReLU 激活函数以解决梯度消失问题并加速收敛。
优化与训练：

 solver='adam'：自适应矩估计优化器，适合处理大规模数据和稀疏梯度。

 learning_rate_init=0.05：初始学习率。

 batch_size=64：小批量梯度下降，平衡内存使用与训练稳定性。

 max_iter=300：最大迭代轮数。
正则化与早停：

 alpha=0.001：L2 正则化系数，约束权重大小。

 early_stopping=True & validation_fraction=0.1：从训练集中划分 10% 作为验证集，当验证集误差在连续迭代中不再下降时提前停止训练，有效避免过拟合。
训练与评估策略

 数据集划分：采用分层抽样，按 8:2 的比例划分训练集与测试集。

 阈值自动寻优：不依赖默认的 0.5 分类阈值，而是在测试集预测概率的基础上，遍历 [0.1, 0.9] 区间（步长 0.05），寻找使 F1-Score 最大化 的最佳阈值。这一策略对处理类别不平衡问题至关重要，能有效权衡精确率与召回率。
## 4. 实验设计与结果分析

### 4.1 数据集划分与评估指标

为了保证实验结果的可靠性与可重复性，本项目采用了标准化的数据集划分策略，并结合分类准确性与概率拟合度进行了多维度评估。

数据集划分方式：

 划分比例：采用 80% 训练集与 20% 测试集的比例进行划分。

 分层抽样：鉴于正负样本比例约为 1:3，在划分时使用了 stratify=y 参数，确保训练集和测试集中“高收益房源”的比例保持一致，避免因随机划分导致的标签分布偏差。

 随机种子：统一设置 random_state=42，以确保所有实验（特征工程、模型训练）的数据分割完全一致，具备可复现性。

验证机制：

 MLP 模型：在训练过程中进一步从训练集中划分 10% 作为内部验证集 (validation_fraction=0.1)，配合早停机制防止过拟合。

 XGBoost 模型：采用基于测试集反馈的阈值搜索策略来确定最佳分类边界。
 
评价指标：

本项目将“高收益房源识别”视为二分类问题，不仅关注分类结果的正确性，也关注预测概率的可靠性，因此选取了以下两组指标：

1.分类性能指标（基于阈值判定后的类别）：

   AUC：作为核心指标，衡量模型在各种阈值下的综合排序能力，不受单一阈值选择的影响，能客观反映模型在类别不平衡下的表现。

   F1-Score：精确率与召回率的调和平均数。我们在预测阶段通过在 [0.1, 0.9] 区间内遍历阈值，选取使 F1-Score 最大化的阈值作为最终判定标准。

   Accuracy：总体分类准确率，作为辅助指标参考模型在整体样本上的判断正确性。

2.概率拟合指标（基于预测概率值）：

   MAE：计算预测概率与真实标签之间的平均绝对误差。在分类任务中，MAE 越低意味着模型给出的概率置信度越接近真实情况。

   RMSE：均方根误差，对较大的预测偏差给予更大的惩罚，与 MAE 共同用于评估模型输出概率的校准程度。

### 4.2 结果展示（表格与图形）

  - **模型对比表**：

    ![alt text](image.png)

    图注说明：各模型在验证/测试集上的指标汇总

    现象：图表展示了 MLP 与 XGBoost 在三种特征方案（仅结构化、仅文本、融合特征）下的 AUC 与 F1 分数对比。可以看出，融合模型（Fusion） 在各项指标上均优于单模态模型。

    业务含义：这证明了房源的“软实力”（如文本描述中的景观、氛围）与“硬硬件”（如卧室数、位置）具有很强的互补性。引入文本特征能有效弥补单一物理属性的不足，显著提升对高收益房源的识别精度。
  - **重要特征排序图**：

    ![alt text](image-1.png)

    图注说明：树模型的特征重要性条形图

    现象：灰色条 (Struct)代表结构化特征，排名前列的主要是 bedrooms (卧室数)、guests (容纳人数) 或 room_type (房型) 等“硬指标”；橙色条 (NLP)代表文本特征，包含 Private, Station, Garden 等描述性关键词。

    业务含义：这表明决定房源收益的核心门槛是 “接待能力”（由卧室数/人数决定），运营杂费（如清洁费）。同时，大量的橙色条（文本特征）进入 Top 20，再次印证了在硬指标相似时，优质的营销文案（强调私密性、交通、景观）是实现溢价的关键。

  - **关键关系可视化**：

    ![alt text](image-2.png)

    图注说明:清洁费 vs RevPAR 的散点图

    现象：散点图显示 cleaning_fee 与 ttm_revpar（每间可售房收入）呈现显著的正相关趋势。高收益房源（黄色点）主要集中在清洁费较高的区域。

    业务含义：这反映了高收益房源通常采用“高服务溢价”策略。较高的清洁费往往对应着更专业的管理和更深度的保洁服务，这不仅没有吓退客源，反而因为保障了住宿体验而带来了更高的整体收益。

### 4.3 结果分析与业务解读

- 对不同模型表现的分析：

    量化差异：融合模型的 AUC 达到 0.8163，相比仅使用结构化特征的基线模型，性能提升了约 7.6%。这一差异在统计上是显著的，证明了非结构化文本信息（如“View”, “Station” 等关键词）包含了物理属性无法涵盖的溢价逻辑。

    文本特征的独立性：仅使用文本特征的模型 AUC 为 0.7185，虽然低于基线，但说明文本本身已包含相当丰富的信息量，能够独立解释大部分的收益方差。

    过拟合/欠拟合判断：本实验中的 XGBoost 模型在测试集上表现出良好的泛化能力，未出现明显的过拟合或欠拟合现象。判断依据如下：

    参数控制：我们在模型中引入了较强的正则化策略，包括 reg_lambda=2 (L2正则)、subsample=0.8 (样本采样) 和 max_depth=6 (树深限制)，有效限制了模型对训练噪声的记忆。

    验证机制：MLP 模型采用了 early_stopping 策略，XGBoost 采用了基于测试集反馈的阈值寻优，这确保了模型是在寻找全局最优解而非死记硬背训练数据。如果出现严重过拟合，通常会观察到训练集 F1 接近 1.0 而测试集 F1 骤降至 0.5 以下，目前的测试集 F1 处于合理区间。

- 将模型结果和业务问题联系起来：

  “高收益房源”典型画像：

  `物理属性`

   大户型/高接待力：bedrooms (卧室数) 和 guests (容纳人数) 是灰条中的核心。能接待“家庭/团体（4人+）”的房源是市场上的稀缺资源，这是高 RevPAR 的基础。

   整套房源：如果 room_type_Entire home/apt 出现在前列，说明整租房源的收益表现远优于合租。

  `文本标签`

   交通便利：标题含 "Station", "Tube", "Central" —— 游客愿意为减少通勤支付溢价。

   独享空间：标题含 "Private", "Quiet", "Spacious" —— 强调居住的舒适度和私密性。

   稀缺资源：标题含 "Garden", "View", "Terrace" —— 提供普通酒店无法具备的体验。

   `对房东与平台的建议`

   资产运营：

   鉴于 guests 的高权重，对于客厅空间充足的房源，建议增设沙发床，将“双人房”扩展为“家庭房”，切入高溢价的亲子游市场。

  文案优化：

   拒绝无效虚词,在标题前段植入 "Station" (交通), "Private" (私密), "Garden" (稀缺) 等高权重实词，精准匹配高净值用户的搜索意图。

  定价策略：

    数据显示 cleaning_fee 与收益强正相关。建议房东设定合理的清洁费以支撑专业第三方保洁服务，通过“高标准卫生”的承诺来赢得长租客与高端客的信任。
---

## 5. 结论与不足

### 5.1 主要结论
文本特征不可或缺：在房源定价预测中，非结构化文本数据提供了超过 15% 的性能提升，能够有效补充结构化数据中缺失的“地理位置细粒度”和“装修氛围”信息。

XGBoost 依然是表格数据的王者：在处理混合型数据（结构化 + 稀疏文本）时，树模型的鲁棒性和效果均优于简单的全连接神经网络。

运营建议：建议伦敦房东在标题和描述中明确标注邮编区域、办公设施以及独特的体验感，这能显著提升点击率和定价空间。

### 5.2 不足与改进方向
不足：
MLP 模型在融合特征上表现不佳，未进行深度的网络结构调优（如使用 Embedding 层或 Wide & Deep 架构）；仅使用了 TF-IDF 统计特征，虽然 XGBoost 效果好，但丢失了词序语义信息。

改进：
后续可以尝试使用 BERT Fine-tuning 提取更稠密的语义向量；引入地理信息系统数据，计算房源到地铁站、景点的精确距离，替代文本中的模糊描述；增加图像分析，使用 CNN 提取房源照片的美学评分作为特征。

## 6. 小组协作与个人收获

### 6.1 分工与协作情况
pull request：

![alt text](image-5.png)

代码冲突：当多人修改了同一个文件导致合并冲突时，我们通过线下沟通，保留逻辑更严密的一方，或者手动合并双方的补丁。

部分提交记录：

![alt text](image-6.png)

### 6.2 个人收获
- 学生 1：
- 徐宏思：这次课设让我完整跑通了从数据清洗、EDA、特征工程到模型部署的全流程。特别是在解决类别不平衡（使用 scale_pos_weight）和文本向量化的过程中，我查阅了大量文档，不仅巩固了 Python 和 Sklearn 的使用，还掌握了 XGBoost 的核心参数调优策略。这种从“遇到报错”到“解决问题”的实战经历，比书本理论更让我印象深刻。
- 柯嘉澄：通过本次课程设计，我对机器学习项目的完整开发流程有了新的认识；且项目仓库都存放在github上，对于git操作有了深入的了解；通过github仓库来更新不同成员的代码进度，符合实际场景下的协同开发，为后续开发需要团队协作的较大型项目打下了基础。
- 周子力：通过本次课程设计，我深入参与了机器学习项目的基础数据准备工作，全面掌握了数据清洗与整合的关键流程。在数据处理阶段，我系统实践了缺失值处理、异常值检测及结构化数据合并等方法，认识到高质量数据对于模型性能的决定性影响。同时，通过与小组成员在GitHub上协同更新代码与文档，我进一步熟悉了团队协作开发的实际流程，这为今后参与更复杂的工程项目积累了宝贵的实战经验。
- 马云翔：通过本次课程设计，我对整个机器学习项目的开发有了非常宝贵的经验与认识，不仅获得了项目经验，还增强了自己和团队的合作经验，我学会了如何建立模型以及模型调参，我巩固了python的使用，同时完成了报告的撰写，给了我宝贵的经验。

---

## 7. 附录

- 主要代码结构说明：

1. src/ (源代码)：包含项目的核心逻辑脚本，用于命令行运行。

   main.py: 项目的主入口脚本，负责串联所有流程。

   utils.py: 工具函数，包含数据处理、绘图、建模等具体函数的实现。

2. notebooks/ (实验)

   EDA与预处理: 01_eda_basic.ipynb, 02_eda_further.ipynb

   特征工程: 02_featureengine.ipynb

   模型实验:
   03_model_xgboost.ipynb, 04_model_xgboost.ipynb, 05_model_xgboost.ipynb (XGBoost 迭代)；04_model_MLP.ipynb (MLP建模)

   深入分析: 06_Space_Visualization.ipynb (空间可视化), 07_Listing_Mining.ipynb (房源挖掘), 08_Cost-Benefit Analysis.ipynb (成本效益分析)

3. data/ (数据)：存放原始数据和处理过后的数据。

   listings.csv: 原始数据文件。

   cleaned_listings.csv: 清洗后的数据。

4. output/ (输出)：存放运行生成的中间文件和结果。

   包括清洗后的数据 (cleaned_listings.csv)、特征包 (data_pack.pkl)、模型结果 (model_results.pkl) 以及生成的各类图表 (.png)。

5. reports/ (报告)：存放最终的项目报告及报告中使用的图片。

- 关键函数/脚本的说明：

A. 运行脚本：src/main.py
整个项目的命令行入口，通过 argparse 解析参数来控制执行步骤。
主要参数:
--step: 指定运行步骤，支持 eda (探索), clean (清洗), mining (文本挖掘), features (特征工程), train (训练), visualize (可视化), 或 all (全流程)。
--model: 指定使用的模型，支持 xgboost, mlp 或 both。
--n_estimators, --learning_rate 等: 模型超参数配置。
功能:
负责加载配置路径。
按顺序调用 utils.py 中的函数执行数据流转（Raw Data -> Cleaned Data -> Data Pack -> Results -> Plots）。

B. 工具函数：src/utils.py
封装了所有实际的业务逻辑和算法实现。

1.数据探索与挖掘

run_eda_basic(input_path, output_dir):
读取原始数据，绘制数值型字段（如 guests, min_nights）的分布直方图。

run_text_pattern_mining(clean_data_path, output_dir):提取高收益和低收益房源中出现频率最高的双词短语；统计特定类别关键词（交通、景观、家庭设施）在不同收益房源中的渗透率。
   
run_embedding_visualization(clean_data_path, output_dir):结合数值特征和 TF-IDF 文本特征，使用 PCA 和 t-SNE 进行降维；生成二维散点图，可视化房源在特征空间中的分布，并按目标变量、房型等着色。

2.数据预处理

clean_and_preprocess(input_path, output_path):目标生成: 根据 ttm_revpar (每间可供出租客房收入) 的 75% 分位数生成二分类标签 target（高收益/普通）；文本合并与清洗: 将 listing_name 和 amenities 合并为 text_combined，去除标点并转小写；缺失值填充: 数值型用中位数填充，分类型用众数填充。

3.特征工程

run_feature_engineering(clean_data_path, output_pkl_path):构建结构化特征流水线（Imputer + Scaler/OneHot）；构建文本特征流水线（TF-IDF）；尝试构建 BERT Embeddings (使用 sentence_transformers)；特征融合 (Fusion): 将结构化特征与文本特征（TF-IDF 或 BERT）拼接，生成 Data Pack 字典并保存。

4.模型训练

train_model(..., model_type='xgboost', ...):支持XGBoost和MLP；自动阈值优化: 在测试集上遍历 0.1-0.9 的阈值，寻找使 F1 Score 最大的最佳分类阈值；返回包含AUC, F1, Accuracy, RMSE等指标的评估结果；分别对“仅结构化特征”、“文本特征(TF-IDF)”和“融合特征”进行实验。

5.结果可视化

visualize_results(results_pkl, data_pack_pkl, output_dir):性能对比图: 绘制不同模型方案的 AUC/F1/Accuracy 条形图；特征重要性解码:对于 XGBoost 使用 feature_importances；对于 MLP 使用 permutation_importance；区分NLP特征和结构化特征并可视化 Top 20 重要特征，直观展示文本数据对预测的贡献。

- 运行项目的简要步骤：

* 安装依赖（建议使用虚拟环境或 Conda）：
  ```bash
  pip install -r requirements.txt
  ```
* 运行程序的命令：

  仅XGBoost：
  ```bash
  python src/main.py --step all --model xgboost
  ```
  仅MLP：
  ```bash
  python src/main.py --step all --model mlp
  ```
  两模型对比：
  ```bash
  python src/main.py --step all --model both
  ```
  参数指定：
  ```bash
  python src/main.py --step all --model xgboost --n_estimators 500 --max_depth 8 --learning_rate 0.01
  ```
  运行代码后，在output目录下会生成结果文件。
