# 机器学习课程设计项目报告

---

## 1. 项目基本信息

- 小组编号：310
- 课题名称：伦敦多模态房源表示的 RevPAR 预测
- 选定城市及范围：伦敦
- 选定时间范围：2024 年 12 月 1 日至 2025-11 月 30 日
- 所用数据表：Listings 
- 项目 Github 仓库地址：https://github.com/ZJUT-CS/ml-course-project-2025-310.git

### 1.1 小组成员与角色分工（固定 4 人）

| 成员   | 姓名   | 学号         | GitHub 用户名 | 主要负责内容（简要）   |
| ------ | ------ | ------------ | ------------- | ---------------------- |
| 学生 1 | 陈彦博 | 302023562025 | cyb620        | 对三个特征进行收益代价分析并可视化，挖掘顶级房源文案模式 |
| 学生 2 | 胡一泓 | 302023562026 | Musiala-826   | 两种传统模型实现与模型训练评估对比分析的撰写 |
| 学生 3 | 徐治勋 | 302023562006 | xzx941        | 原始数据清洗、分析与3套特征向量的选择和构造 |
| 学生 4 | 陶睿   | 302023562008 | Andytao47     | 普通神经网络的实现与文本结构数据集Sentence-BERT方法与模型训练评估的实现 |

---

## 2. 问题背景与数据集说明

### 2.1 业务背景与研究问题

随着 Airbnb 等短租平台的普及，城市房源的供给日益丰富，房东和平台如何在众多房源中识别“高收益房源”、合理制定价格与运营策略，成为一个具有现实价值的问题。RevPAR（Revenue per Available Room，可售房间收益）综合考虑了价格与入住率，是衡量短租房源收益能力的核心指标。

本项目聚焦伦敦这一成熟短租市场，在给定时间范围（2024‑12 至 2025‑11）内，利用 AirROI 提供的房源静态数据，研究如何通过多模态特征表示（结构化特征 + 文本特征）预测房源是否为“高 RevPAR 房源”。具体而言：

- 本项目是一个**二分类任务**，目标是预测房源是否属于“高 RevPAR”；
- 以 `London_listing.csv` 中的 `ttm_revpar_native`为基础，在非缺失样本上计算 75% 分位数阈值，将
  - RevPAR ≥ 该阈值的房源标记为 1（高 RevPAR），
  - 其余房源标记为 0（非高 RevPAR）。

该问题的业务价值体现在：

- 对平台而言，可以用于挖掘新兴优质房源、推荐排序、精细化流量分配等；
- 对房东而言，有助于理解“高 RevPAR 房源”的关键特征（房型、位置、价格、评分、设施等），指导定价和装修/运营决策；
- 对房客而言，通过提升平台整体供给质量和排序合理性，间接改善选房体验。

### 2.2 数据来源与筛选规则

本项目的数据来源于 **AirROI Data Portal**，通过其公开接口下载伦敦地区 Airbnb 房源的数据表：

- **Listings Data（房源表）**：  
  包含房源基础属性（房型、卧室数、经纬度、设施配置、是否为 superhost 管理等），以及过去一年或近 90 天的聚合运营指标，如 `ttm_revpar_native`、`ttm_avg_rate_native`、`ttm_available_days`、`ttm_total_days`、多维评分字段等，是构建结构化特征和目标变量的数据源。

在原始 `London_listing.csv` 基础上，数据筛选与构造流程如下：

1. **城市与时间范围约束**
   - 选定城市字段为“伦敦”的房源，并限定在 2024‑12 至 2025‑11 的统计窗口内具有完整 TTM 指标的样本；
2. **目标变量可用性筛选**
   - 在上述样本上计算 RevPAR 的 75% 分位数，构造高/低 RevPAR 标签 `y`，输出 `London_listing_target.csv`；
3. **建模样本划分**  
   - 使用 `data_split.py` 对 `London_listing_target.csv` 按 **Train/Val/Test = 70%/15%/15%** 随机划分为 `train_orgin.csv`、`val_orgin.csv`、`test_orgin.csv`；  
   - 划分时对标签 `y` 做分层采样，使三份数据中高/低 RevPAR 比例保持约 **1:3**；  
   - 划分后，总样本量约 300 条，其中训练集约 210 条、验证集和测试集各约 45 条。

在后续特征工程中，围绕以下关键字段构造三套特征：

- **核心结构化特征示例**：
  - 房源规模与类型：`room_type`、`listing_type`、`bedrooms`、`beds`、`baths`、`guests`；
  - 价格与可售情况：`ttm_avg_rate_native`、`ttm_available_days`、`ttm_total_days`、派生比率 `ttm_available_ratio`（由`ttm_available_days` / `ttm_total_days`计算得到）；
  - 位置与管理属性：`latitude`、`longitude`、`professional_management`、`instant_book`、`superhost`、`cancellation_policy`；
  - 口碑与评分：`num_reviews` 以及 7 个评分维度 `rating_overall`、`rating_accuracy`、`rating_checkin`、`rating_cleanliness`、`rating_communication`、`rating_location`、`rating_value`。
- **文本特征字段**：
  - 房源标题 `listing_name`：高度概括房源卖点及定位；
  - 设施列表 `amenities`：反映基础设施和差异化配置，是刻画房源“丰富程度”和舒适性的关键信息。

### 2.3 预期目标与分析思路

在数据获取与预处理阶段，本项目的目标并不仅是“清洗数据”，而是为后续多模型对比与业务解释构建一套结构清晰、可复现的特征体系。具体预期目标包括：

- 基于结构化字段与文本字段，构建三套互相可比的特征方案：
  - 01：仅使用结构化特征的 `train_01/val_01/test_01`；
  - 02：仅使用文本特征（标题 + 设施）的 `train_02/val_02/test_02`；
  - 03：结构化与文本简单拼接的融合特征 `train_03/val_03/test_03`；
- 在三套特征上统一使用同一 Train/Val/Test 划分与标签定义，保证后续模型性能对比公平；
- 通过缺失值处理、异常值修正、数值变换、类别编码、文本向量化和特征筛选等步骤，尽可能提高特征与 RevPAR 的相关性，降低噪声和冗余。

整体分析思路为：先在结构化与文本模态上分别完成特征工程并输出 01/02 套数据，再将两者融合为 03 套特征；随后在三套特征上分别训练 Logistic Regression 与 XGBoost 等模型，对比不同模态与特征工程策略对“高 RevPAR 房源识别能力”的影响，并结合特征重要性与业务语义给出高收益房源画像及运营建议。

---

## 3. 方法与模型设计

### 3.1 数据预处理与特征工程

本项目在“数据集获取与特征构造”环节的工作主要集中在两个方面：一是围绕 RevPAR 构造标签并统一划分 Train/Val/Test；二是分别在结构化模态与文本模态上设计特征工程流程，并最终形成三套可对比的特征数据集。

#### 3.1.1 标签构造与基础样本

- 以 `London_listing.csv` 为原始房源表，通过脚本 `target_listing.py` 从中选取 `ttm_revpar_native`，在非缺失样本上计算 75% 分位数，将 RevPAR 位于 Top 25% 的房源标记为 1，其余标记为 0，输出 `London_listing_target.csv`；
- 使用 `data_split.py` 在 `London_listing_target.csv` 上按 **70%/15%/15%** 比例、对 `y` 分层随机划分得到 `train_orgin.csv`、`val_orgin.csv`、`test_orgin.csv`，作为后续所有特征工程的统一起点。

#### 3.1.2 结构化特征工程（01 套特征）

1. **字段初筛与派生特征**

   - 从 `*_orgin.csv` 中人为初筛与房源规模、价格、位置、管理属性和评分相关的字段，如 `room_type`、`listing_type`、`bedrooms`、`beds`、`baths`、`guests`、`min_nights`、`cancellation_policy`、`instant_book`、`professional_management`、`superhost`、`latitude`、`longitude`、`ttm_avg_rate_native`、`ttm_available_days`、`ttm_total_days`、`num_reviews` 以及多维评分字段；
   - 基于 `ttm_available_days` 和 `ttm_total_days` 派生开放预订比例特征 `ttm_available_ratio`，用于度量房源在统计期内的开放度与“热度”。

2. **缺失值与异常值处理**  
   - `guests`、`bedroom` 缺失过多，约在0.4左右，不适合统一填充，直接删去；
   - `professional_management`特征的非缺失部分中只有一个值为True其余均为False，可以看出此特征对分类意义不大，故直接删除
   - 将 `instant_book` 缺失视作一种独立状态，统一填充为 `"Unknown"`；  
   - 对 `beds` 采用分层中位数填充策略：先按 `listing_type` 分组填充，若依旧缺失，再按 `room_type` 分组填充，最后对仍缺失样本使用全局中位数；  
   - 对 `min_nights` 使用全局中位数填补，对 `cancellation_policy` 使用全局众数填补；  
   - 对存在极端值的计数/金额类变量通过后续的对数变换和标准化减弱长尾影响。

3. **数值特征变换与标准化**

   - 对 `beds`、`baths`、`latitude`、`longitude` 以及 7 个评分字段等连续变量，在训练集上计算均值和标准差，进行 Z‑Score 标准化，并将同一参数应用到验证集和测试集；
   - 对分布高度右偏的特征（`ttm_avg_rate_native`、`num_reviews`、`min_nights`等），先在非负部分进行 \(\log(1+x)\) 变换，然后再做 Z‑Score 标准化，从而缓解长尾问题、提升模型稳定性；
   - `ttm_available_ratio` 本身位于 [0,1] 区间且分布较为稳定，在本实验中保持原尺度参与建模。

4. **计算数值特征间相关系数**  
   - 选取 15 个核心数值特征（`beds`、`baths`、`min_nights`、`latitude`、`longitude`、`ttm_avg_rate_native`、`ttm_available_ratio`、`num_reviews` 以及 7 个 `rating_*` 评分字段），在训练集上计算 Pearson 相关系数矩阵，并绘制如下热力图；  

   ![结构化数值特征相关系数热力图](../outputs/numeric_corr_heatmap.png)

   - 从图中可以看到，7 个评分相关特征之间形成一块明显的高相关“红色方块”，说明各评分维度在信息上高度重叠，为后续使用 PCA 将其合并为单一综合评分提供了依据；    
   - `ttm_avg_rate_native` 与 `beds`、`baths` 存在一定正相关关系，反映更大的房源通常会有更高的定价，但这两者对于房源来说是两个不同维度的描述特征，蕴含不同信息，无需合并；  
   - 经纬度与其他特征的线性相关性整体偏弱，更多通过后续模型在非线性决策边界中发挥作用，而无需在本阶段做额外变换或合并处理。

5. **评分特征降维（PCA 合并）**  
   - 在训练集上使用 PCA 对 7 个评分维度进行降维，提取第一主成分 `rating_pc1` 作为“综合评分”指标；  
   - 使用同一 PCA 变换矩阵对验证集和测试集进行投影，并在三份数据集中用单一的 `rating_pc1` 替代原始 7 个评分字段。

6. **类别特征编码与稀有类别处理**  
   - 观察类别特征，可以发现`listing_type`完全唯一决定了`room_type`，因此`room_type`可以直接删除；
   - 对 `listing_type` 统计训练集频率，将占比低于 1% 的稀有类别合并为 `"Other"`，在统一类别集合的基础上对 Train/Val/Test 做 One‑Hot 编码；  
   - 对 `instant_book` 使用 One‑Hot 编码，并在类别集合中显式保留 `"Unknown"`；  
   - 对 `cancellation_policy` 按政策严格程度定义有序类别（Flexible → Moderate → Firm → Strict → Super Strict 30 Days → Super Strict 60 Days），映射为递增整数；  
   - 对 `superhost` 统一映射为 0/1。

7. **特征相关性分析与筛选**  
   - 在训练集上计算所有特征与标签 `y` 的 Pearson 相关系数，并按绝对值排序，识别出相关性极低、业务解释力弱的特征。下表给出了与 `y` 相关性绝对值排名前 10 的特征示例（保留三位小数，仅展示 \|corr\|）：  

     | 特征                                   | \|corr\| |
     | -------------------------------------- | -------: |
     | ttm_available_ratio                    |   0.508  |
     | ttm_avg_rate_native                    |   0.419  |
     | baths                                  |   0.352  |
     | listing_type_Entire rental unit        |   0.266  |
     | listing_type_Private room in home      |   0.230  |
     | beds                                   |   0.230  |
     | instant_book_Unknown                   |   0.224  |
     | instant_book_False                     |   0.218  |
     | listing_type_Private room in rental unit | 0.196  |
     | latitude                               |   0.151  |

   - 在此基础上，训练一个带 L1 正则的 Logistic Regression，对特征进行稀疏化约束，仅保留权重绝对值大于 0 的特征。下表展示了若干权重绝对值较大的特征示例：  

     | 特征                              | \|coef\| |
     | --------------------------------- | -------: |
     | ttm_available_ratio               |   0.839  |
     | ttm_avg_rate_native               |   0.744  |
     | baths                             |   0.291  |
     | num_reviews                       |   0.238  |
     | instant_book_Unknown              |   0.223  |
     | rating_pc1                        |   0.087  |
     | latitude                          |   0.068  |
     | listing_type_Entire rental unit   |   0.039  |
     | cancellation_policy               |   0.003  |

   - 综合相关系数与 L1 模型的结果，保留所有 L1 逻辑回归中权重不为 0 的特征，并删除相关性较低且业务解释力弱的特征（如 `instant_book_True`、部分稀有 `listing_type_*` 哑变量等），形成 13 个核心结构化特征，在保证信息量的前提下降低维度与噪声，构建出 `train_01.csv`、`val_01.csv`、`test_01.csv`。

#### 3.1.3 文本特征工程（02 套特征）
1. **文本字段选择与清洗**  
   - 选取房源标题 `listing_name` 与设施列表 `amenities` 作为文本信息来源；  
   - 对 `listing_name`：统一小写、去除标点与特殊字符、合并多余空白，并按空格切分为 token，同时去除英文停用词；  
   - 对 `amenities`：按逗号和换行符拆分为设施项，去掉首尾空格和引号并小写化，过滤空字符串。

2. **TF‑IDF 文本向量化**

   - 对标题 `listing_name` 使用 `TfidfVectorizer`，结合自定义预处理/分词函数：
     - `ngram_range=(1, 2)`（unigram + bigram）；
     - `max_features=400`，`min_df=2`，`max_df=0.7`；
   - 对设施 `amenities` 使用基于设施项的 `TfidfVectorizer`：
     - 只使用 unigram；
     - `max_features=120`，`min_df=2`；
   - 在训练集上拟合两个 TF‑IDF 向量化器，并在验证集和测试集上仅做 `transform`，保证所有文本特征使用同一词汇表和权重。

3. **SVD 降维与标准化**

   - 将标题 TF‑IDF 和设施 TF‑IDF 按列拼接形成高维稀疏向量，在训练集上使用 `TruncatedSVD(n_components=50, random_state=42)` 将其降维到 50 维；
   - 在训练集上对 50 维文本特征进行 StandardScaler 标准化，并将同一 scaler 应用到验证集和测试集；
   - 以 `text_feature_0`–`text_feature_49` 命名 50 个文本特征维度，分别输出为 `train_02.csv`、`val_02.csv`、`test_02.csv`（均包含文本特征和标签 `y`）。

4. **Sentence-BERT (SBERT) 深度文本表示（02 SBERT 套特征）**
   - 为了捕捉更深层的语义信息，本项目尝试了基于预训练语言模型的文本表示方法。
   - **模型选择**：使用轻量级且高效的 `all-MiniLM-L6-v2` 模型（输出维度 384）。
   - **编码流程**：将预处理后的文本（标题 + 设施）输入模型，获取句向量嵌入。
   - **降维处理**：由于样本量较小（仅 ~200），384 维并未显著优于低维，且容易过拟合。因此，使用 PCA 将 SBERT 嵌入降维至 50 维，与 TF-IDF 方案保持维度一致性，便于对比。
   - **标准化**：同上，对降维后的特征进行 StandardScaler 标准化。
   - 输出文件名：`train_02_sbert.csv`、`val_02_sbert.csv`、`test_02_sbert.csv`。

#### 3.1.4 多模态融合特征工程（03 套特征）

- 对于 Train/Val/Test 三个划分，分别从 `*_01.csv`（结构化特征）和 `*_02.csv`（文本特征）中读取样本，检查两侧标签 `y` 的顺序与取值完全一致；
- 在去除重复的标签列后，将结构化特征和文本特征按列简单拼接，得到融合特征矩阵，并重新附加标签 `y`；
- 最终生成融合特征数据集 `train_03.csv`、`val_03.csv`、`test_03.csv`，为后续比较“结构化 / 文本 / 融合”三种特征方案下的模型表现提供统一输入。

对于 **SBERT 特征**，采用完全相同的融合逻辑，生成 `train_03_sbert.csv` 等文件，用于评估深度文本表示带来的多模态增益。

### 3.2 模型选择与设计

本项目为 **二分类任务**：预测房源是否为“高 RevPAR”（记为类别 1），类别比例约为 **类别0:类别1 ≈ 3:1**，且训练集规模较小（每套特征方案训练集约 210 条）。针对数据规模、特征类型（结构化/文本/融合）与可解释性需求，本实验选择三类模型进行对比：

#### 3.2.1 Logistic Regression（逻辑回归模型）

- **选择原因**：
  - **小样本友好**：线性模型参数量相对可控，因此在数据量较少时不容易过拟合，这使它成为一个可靠的对比基准。
  - **可解释性强**：模型的系数直接告诉我们每个特征对结果的影响方向和大小，便于理解和应用。
  - **概率输出稳定**：可输出 \(P(y=1)\)，便于在验证集做**决策阈值调优**，改善少数类识别。
- **适用性与局限**：
  - 适合刻画近似线性可分关系；面对复杂非线性或特征交互时能力受限。
  - 对高维文本特征（尤其存在噪声/稀疏）可能出现“信号不足”导致性能偏弱。

结合实验结果，Logistic Regression 在 **结构化特征（01）** 上表现较强（测试集 **F1(1)=0.769，AUC=0.971**），但在 **文本特征（02）** 上效果较弱（测试集 **F1(1)=0.111，AUC=0.578**），说明线性可分假设对文本方案的拟合能力有限。

#### 3.2.2 XGBoost（梯度提升树模型）

- **选择原因**：
  - **非线性建模能力强**：能够自动学习特征交互与非线性边界，通常优于线性模型。
  - **鲁棒性与泛化更好**：通过树结构与集成学习降低偏差，并可用多种正则化/采样策略控制方差。
  - **适配多模态特征**：在融合特征（结构化+文本）下，可更充分地利用互补信息。
- **适用性与局限**：
  - 超参数较多，需谨慎调参以避免小样本过拟合；可解释性弱于线性模型，但可结合特征重要性做补充解释。

结合实验结果，XGBoost 在 **结构化特征（01）** 上取得本次实验最佳之一（测试集 **F1(1)=0.833，AUC=0.979**）；在 **文本特征（02）** 上也明显优于 Logistic（测试集 **F1(1)=0.424，AUC=0.618**），体现了非线性模型对文本表示更友好。

#### 3.2.3 Multi-Layer Perceptron (MLP, 多层感知机)

- **选择原因**：
  - **适应高维与非线性**：神经网络通过层级结构和激活函数，能够灵活拟合高维特征（如文本嵌入）与复杂交互。
  - **多模态潜力**：对于不同分布的模态拼接（结构化+文本），MLP 有潜力通过隐藏层自动学习模态间的融合权重。
- **适用性与局限**：
  - 需要较多的调参（学习率、层数、Dropout 等）且对小样本容易过拟合（需配合 Dropout 和强正则化）。
  - 在本实验中，MLP 被用于测试 **TF-IDF** 与 **SBERT** 两种文本表示在深度模型下的表现差异。

结合实验结果，MLP 在 **SBERT 多模态融合（03 SBERT）** 上取得了比 TF-IDF 融合更好的效果（F1=0.583 vs 0.353），证明了深度特征更适合深度模型；但整体仍弱于 XGBoost，可能受限于仅 200 条的训练样本，导致网络难以充分训练。

### 3.3 超参数设置与训练细节

- 各模型的关键超参数（例如：树的数量、深度、学习率、正则化系数等）。
- 调参方法：
  - 网格搜索 / 随机搜索 / 手动调参。
  - 交叉验证设置（k 折、留出法等）。
- 训练环境与实现说明：
  - 使用的框架（如 scikit-learn、XGBoost、LightGBM、PyTorch 等）。
  - 若有 GPU/CPU 特殊说明可简单写明。

本实验对三套特征向量（01 结构化 / 02 文本 / 03 融合）均采用**同一训练-验证-测试流程**，保证对比公平；并围绕“类别不平衡”问题，统一使用 **F1(正类)** 驱动调参和阈值选择。

#### 3.3.1 通用训练设置

- **数据划分**：对每套特征均使用固定的 Train/Val/Test 划分（约 **210/45/45**），类别比例在三份数据中保持约 **3:1**。
- **调参方法**：`GridSearchCV` 网格搜索 + `StratifiedKFold(n_splits=5)` 分层 5 折交叉验证。
- **核心评分指标**：以 **F1(正类，pos_label=1)** 作为 `GridSearchCV(scoring=...)` 指标，避免 Accuracy 在类别不平衡下产生误导。
- **阈值调优**：在得到最优模型后，用验证集预测概率 \(P(y=1)\) 在 \([0.1, 0.9]\) 上搜索候选阈值（步长约 0.05），选择使验证集 **F1(1)** 最大的阈值，并用该阈值在测试集评估。
- **评估指标（测试集）**：Accuracy、Precision(1)、Recall(1)、F1(1)、AUC。
- **实现环境**：Python + `scikit-learn`（建模/交叉验证/指标）+ `Logistic Regression`/`xgboost`；随机种子 `random_state=42`。

#### 3.3.2 Logistic Regression：超参数与不平衡处理

- **不平衡处理**：在损失函数层面使用 `class_weight`，候选集合包含：
  - `'balanced'`
  - \(\{0:1,\,1:2\}\)、\(\{0:1,\,1:3\}\)、\(\{0:1,\,1:4\}\)
- **网格搜索参数**：
  - `C ∈ {0.01, 0.1, 1, 10}`
  - `penalty='l2'`, `solver='liblinear'`, `max_iter=1000`
- **验证集最优阈值**：
  - 01：0.35；02：0.55；03：0.55

#### 3.3.3 XGBoost：超参数与不平衡处理

- **不平衡处理**：使用 `scale_pos_weight = #neg/#pos`（训练集中约为 **2.96**）对正类加权，提升少数类召回与 F1。
- **网格搜索参数**：
  - `n_estimators ∈ {100, 200}`
  - `max_depth ∈ {3, 5}`
  - `learning_rate ∈ {0.05, 0.1}`
  - `subsample ∈ {0.8, 1.0}`
  - `colsample_bytree ∈ {0.8, 1.0}`
  - 其余基础参数：`objective='binary:logistic'`, `eval_metric='logloss'`, `tree_method='hist'`, `random_state=42`
- **验证集最优阈值**：
  - 01：0.20；02：0.10；03：0.45

#### 3.3.4 MLP（多层感知机）：超参数与不平衡处理

- **模型架构**：

  - 隐藏层结构：根据特征方案调整（详见下表）
  - 激活函数：`ReLU`
  - 输出激活：`Sigmoid`（二分类概率）
  - Dropout 率：`0.3–0.4`（防止过拟合）

- **不平衡处理**：在损失函数层面使用**样本权重**（sample weights），根据训练集类别比例计算：

  - 正类权重 = $\frac{N}{2 \times N_{pos}}$，负类权重 = $\frac{N}{2 \times N_{neg}}$
  - 实际权重比例约为 **负类:正类 ≈ 0.67:1.98**

- **训练策略**：

  - 优化器：`Adam`
  - 学习率：`0.001–0.005`（根据特征方案调整）
  - 批次大小：`16–32`（根据特征方案调整）
  - 最大轮数：`100`
  - **早停机制**：`patience=15`，基于验证集损失提前终止

- **最优超参数配置**（通过手动调参确定）：

| 特征方案       | 学习率 | 隐藏层    | Dropout | 批次大小 |
| -------------- | -----: | --------- | ------: | -------: |
| 01 结构化      |  0.005 | [64, 32]  |     0.4 |       16 |
| 02 TF-IDF 文本 |  0.002 | [128, 64] |     0.3 |       32 |
| 03 TF-IDF 融合 |  0.001 | [32, 16]  |     0.4 |       32 |

- **SBERT 特征预处理**：

  - 使用 `all-MiniLM-L6-v2` 模型生成 384 维句向量
  - 应用 PCA 降维至 **50 维**，与 TF-IDF 特征维度保持一致，同时缓解过拟合

- **实现环境**：Python + `PyTorch`（神经网络）+ `scikit-learn`（评估指标）+ `sentence-transformers`（SBERT）

---

## 4. 实验设计与结果分析

### 4.1 数据集划分与评估指标

本实验在构造标签 `y` 后，统一在 `London_listing_target.csv` 上完成 Train/Val/Test 划分，并在所有特征方案（01 结构化、02 文本、03 融合）中严格复用同一划分，避免数据泄露和评估不一致。

#### 4.1.1 数据集划分方式

- **划分依据与比例**

  - 以带标签的 `London_listing_target.csv` 为起点，使用 `train_test_split` 在保证类别分布大致一致的前提下，对标签 `y` 做**分层随机划分**；
  - 首先将数据集划分为 70% 训练集与 30% 临时集；
  - 再将 30% 临时集等比例划分为验证集和测试集（各占总样本 15%），最终得到约 **210/45/45** 的 Train/Val/Test 样本规模；
  - 由于使用分层采样，三份数据中高 RevPAR（正类 1）与低 RevPAR（负类 0）的比例均保持在约 **1:3**。

- **多模态一致性**
  - 划分操作在原始带标签文件上完成，输出为 `train_orgin.csv`、`val_orgin.csv`、`test_orgin.csv`；
  - 后续结构化预处理（生成 `*_01.csv`）、文本预处理（生成 `*_02.csv`）以及结构化+文本融合（生成 `*_03.csv`）均在各自对应的 orgin 数据集上进行，不再对样本做新增或删除；
  - 因此，对于任一索引 \(i\)，`train_01[i]`、`train_02[i]` 和 `train_03[i]` 对应的都是同一条房源记录，且标签 `y` 完全一致。

#### 4.1.2 评估指标体系

由于本项目为**严重类别不平衡的二分类任务**（高 RevPAR 约占 1/4），单一 Accuracy 容易掩盖少数类识别能力。因此，本实验在验证集与测试集上采用如下指标体系：

- **Accuracy（准确率）**：整体预测正确的比例，用于衡量模型整体分类能力，但在类别不平衡下并非核心指标；
- **Precision(1)（正类精确率）**：在被预测为“高 RevPAR”的房源中，真正高 RevPAR 的比例，反映模型对高收益房源推荐的可靠程度；
- **Recall(1)（正类召回率）**：在所有真实的高 RevPAR 房源中，被模型成功识别出来的比例，体现对高收益房源的覆盖程度；
- **F1(1)（正类 F1 值）**：Precision(1) 与 Recall(1) 的调和平均，是本实验最核心的模型选择与阈值调优指标；
- **AUC（ROC 曲线下面积）**：基于预测概率衡量模型区分正负类的整体能力，与具体阈值无关，补充刻画模型对高/低 RevPAR 可分性的强弱。

在训练阶段：

- 使用训练集进行模型拟合，并在**验证集**上以正类 F1 值 \(F1(1)\) 作为主导指标进行超参数搜索（例如 XGBoost 的树深度、学习率、`scale_pos_weight` 等）；
- 在得到每个模型的最优超参数后，进一步在验证集上对预测概率 \(P(y=1)\) 进行阈值搜索（从 0.1 到 0.9 的多个候选阈值），选取使 **F1(1)** 最大的阈值；
- 最终在**测试集**上以该最优阈值进行评估，并报告 Accuracy、Precision(1)、Recall(1)、F1(1)、AUC 等指标，以衡量模型在未知数据上的真实泛化表现。

### 4.2 结果展示（表格与图形）

- 建议至少包含：
  - **模型对比表**：各模型在验证/测试集上的指标汇总。
  - **重要特征排序图**：如树模型的特征重要性条形图。
  - **关键关系可视化**：例如 RevPAR 与价格、评分、地理位置的关系。
- 每个图表配简短图注，说明看到了什么现象。

#### 4.2.1 模型对比表

**表 4-1 Logistic Regression（加权 + 阈值调优）测试集结果**

| 特征方案                   | 最佳阈值 | Accuracy | Precision(1) | Recall(1) |  F1(1) |    AUC |
| -------------------------- | -------: | -------: | -----------: | --------: | -----: | -----: |
| 01 结构化（Structured）    |     0.35 |   0.8667 |       0.6667 |    0.9091 | 0.7692 | 0.9706 |
| 02 文本（Text-only）       |     0.55 |   0.6444 |       0.1429 |    0.0909 | 0.1111 | 0.5775 |
| 03 融合（Structured+Text） |     0.55 |   0.7333 |       0.4286 |    0.2727 | 0.3333 | 0.7834 |

**表 4-2 XGBoost（加权 + 阈值调优）测试集结果**

| 特征方案                   | 最佳阈值 | Accuracy | Precision(1) | Recall(1) |  F1(1) |    AUC |
| -------------------------- | -------: | -------: | -----------: | --------: | -----: | -----: |
| 01 结构化（Structured）    |     0.20 |   0.9111 |       0.7692 |    0.9091 | 0.8333 | 0.9786 |
| 02 文本（Text-only）       |     0.10 |   0.5778 |       0.3182 |    0.6364 | 0.4242 | 0.6176 |
| 03 融合（Structured+Text） |     0.45 |   0.9111 |       0.8182 |    0.8182 | 0.8182 | 0.9519 |

**表 4-3 MLP（标准特征 vs SBERT 特征）测试集结果**

| 模型与特征方案               | 最佳阈值 | Accuracy | Precision(1) | Recall(1) |  F1(1) |    AUC |
| ---------------------------- | -------: | -------: | -----------: | --------: | -----: | -----: |
| **MLP (Standard)**           |          |          |              |           |        |        |
| 01 结构化 (Structured)       |      0.5 |   0.8444 |       0.6429 |    0.8182 | 0.7200 | 0.9118 |
| 02 文本 (TF-IDF)             |      0.5 |   0.7111 |       0.4000 |    0.3636 | 0.3810 | 0.5882 |
| 03 融合 (Hybrid TF-IDF)      |      0.5 |   0.7556 |       0.5000 |    0.2727 | 0.3529 | 0.7647 |
| **MLP (SBERT)**              |          |          |              |           |        |        |
| 02 SBERT 文本 (SBERT-PCA)    |      0.5 |   0.6444 |       0.2727 |    0.2727 | 0.2727 | 0.5909 |
| 03 SBERT 融合 (Hybrid SBERT) |      0.5 |   0.7778 |       0.5385 |    0.6364 | 0.5833 | 0.8182 |

从 MLP 的结果可见：

- **结构化特征表现尚可**（F1=0.720），但弱于 XGBoost (0.833)。
- **SBERT 融合显著优于 TF-IDF 融合**：在融合场景下，引入 SBERT 特征使 MLP 的 F1 从 **0.353** 提升至 **0.583**，AUC 从 **0.765** 提升至 **0.818**。这表明神经网络能更好地利用稠密的 SBERT 语义向量，而非稀疏的 TF-IDF。
- **样本约束**：整体上 MLP 仍未能超越 XGBoost，主要原因推测为训练数据量过少（~210 条），限制了神经网络的泛化能力。

从表格可见：

- **01 结构化特征整体最强**两类模型下均取得最高或接近最高的 F1/AUC，说明结构化字段包含最主要的预测信号。
- **02 文本特征单独使用时较弱**：Logistic 几乎无法稳定识别正类（F1 很低），而 XGBoost 能显著提升 Recall 与 F1，体现非线性模型对文本表示的适配性更好。
- **03 融合特征在 XGBoost 下接近最优**（F1=0.818，AUC=0.952），说明文本可能提供一定互补信息；但在 Logistic 下融合提升有限（可能与高维噪声/共线性有关）。

#### 4.2.2 ROC 曲线

- **图 4-1 Logistic ROC（01/02/03）**：figures/logistic_roc.png  
  图中 01 的 AUC 接近 1，`区分能力强`；02 的 AUC 接近随机水平，说明文本单模态下`可分性较弱`。

<div align="center">

![Logistic Regression ROC曲线](../outputs/Logistic%20Regression%20ROC曲线.png)

</div>

- **图 4-2 XGBoost ROC（01/02/03）**：figures/xgb_roc.png
  XGBoost 在 01/03 上 AUC 仍保持较高，同时在 02 上 AUC 有一定提升。

<div align="center">

![XGBoost ROC曲线](../outputs/XGBoost%20ROC曲线.png)

</div>

- **图 4-3 MLP ROC（01/02/03）**：figures/mlp_roc.png
  MLP 在 01 结构化特征上 AUC=0.901，表现良好；02 文本特征上 AUC=0.596，接近随机水平；03 融合特征上 AUC=0.789，介于两者之间。

<div align="center">

![MLP ROC曲线](../outputs/MLP%20ROC曲线.png)

</div>

- **图 4-4 MLP-SBERT ROC（02/03 SBERT）**：figures/mlp_sbert_roc.png
  MLP-SBERT 在 SBERT 融合特征（03）上 AUC=0.818，显著优于 TF-IDF 融合（0.789），体现深度语义表示对神经网络的增益。

<div align="center">

![MLP-SBERT ROC曲线](../outputs/MLP-SBERT%20ROC曲线.png)

</div>

#### 4.2.3 混淆矩阵

- **图 4-5 Logistic 混淆矩阵**：figures/logistic_confusion_matrices.png  
  重点观察`正类`（1）的 TP/FP/FN：文本特征下 FN 较多，导致 Recall/F1 偏低。

![alt text](<../outputs/Logistic Regression 混淆矩阵.png>)

- **图 4-6 XGBoost 混淆矩阵**：`figures/xgb_confusion_matrices.png`  
  文本特征下 XGBoost 能显著减少 FN（提高 Recall），从而带来 F1 提升。

![alt text](<../outputs/XGBoost 混淆矩阵.png>)

- **图 4-7 MLP 混淆矩阵**：figures/mlp_confusion_matrices.png  
  MLP 在结构化特征（01）上 TP=9、FN=2，Recall 较高；文本特征（02）下 FN 显著增加，正类识别能力下降；融合特征（03）表现介于两者之间。

![alt text](<../outputs/MLP 混淆矩阵.png>)

- **图 4-8 MLP-SBERT 混淆矩阵**：figures/mlp_sbert_confusion_matrices.png  
  MLP-SBERT 在 SBERT 融合特征上 TP=7、FN=4，相比 TF-IDF 融合（TP=3、FN=8）有明显改善，验证了 SBERT 语义表示对神经网络的提升效果。

![alt text](<../outputs/MLP-SBERT 混淆矩阵.png>)

#### 4.2.4 少数类 F1 柱状图

- **图 4-9 Logistic 少数类 F1 对比**：figures/logistic_f1_bar.png

<div align="center">

![Logistic Regression F1对比图](../outputs/Logistic%20Regression%20F1对比图.png)

</div>

- **图 4-10 XGBoost 少数类 F1 对比**：figures/xgb_f1_bar.png

<div align="center">

![XGBoost F1对比图](../outputs/XGBoost%20F1对比图.png)

</div>

- **图 4-11 MLP 少数类 F1 对比**：figures/mlp_f1_bar.png

<div align="center">

![MLP F1对比图](../outputs/MLP%20F1对比图.png)

</div>

- **图 4-12 MLP-SBERT 少数类 F1 对比**：figures/mlp_sbert_f1_bar.png

<div align="center">

![MLP-SBERT F1对比图](../outputs/MLP-SBERT%20F1对比图.png)

</div>

柱状图直观展示三套特征对`少数类`识别的影响：01 最强，02 最弱；在 XGBoost 下 03 与 01 接近，融合方案更具潜力。MLP 在结构化特征上表现较好，而 MLP-SBERT 在融合特征上相比 TF-IDF 有明显提升。

#### 4.2.5 重要特征排序图

- 本小节 **仅展示结构化特征（01 Structured）** 的特征排序结果。

- **图 4-7 Logistic（结构化特征）系数 Top-N（按绝对值）**：figures/logistic_top_coefficients_structured.png

![alt text](<../outputs/Logistic Regression  结构化特征重要特征排序图.png>)

- **图 4-8 XGBoost（结构化特征）特征重要性 Top-N**：figures/xgb_top_importances_structured.png

![alt text](<../outputs/XGBoost  结构化特征重要特征排序图.png>)

- **MLP 模型特征重要性说明**

  MLP（多层感知机）作为深度神经网络模型，与 Logistic Regression 的线性系数或 XGBoost 的树结构特征重要性不同，**不具备直接的特征重要性属性**。这是因为：

  1. **非线性变换**：MLP 通过多层隐藏层和非线性激活函数（ReLU）对输入特征进行复杂的非线性变换，每个特征对最终预测的贡献被分散到网络的权重矩阵中，无法通过简单的系数值量化。
  
  2. **特征交互隐式学习**：与树模型显式分裂不同，MLP 隐式学习特征间的交互关系，单个特征的独立贡献难以解耦。

  因此，MLP 和 MLP-SBERT 模型在本节不提供传统特征排序图，其模型效果主要通过 ROC 曲线、混淆矩阵和 F1 对比图进行评估。

#### 4.2.6 预测概率分布图

该图展示模型输出 \(P(y=1)\) 在正负类上的`分布重叠程度`：分布分离`越明显`，模型区分能力`越强`；文本特征下 Logistic 的两类分布更易重叠，而 XGBoost 分离程度更好。

- **图 4-9 Logistic 预测概率分布（按真实类别分组）**：figures/logistic_score_distribution.png

![alt text](<../outputs/Logistic Regression  预测概率分布图.png>)

- **图 4-10 XGBoost 预测概率分布（按真实类别分组）**：figures/xgb_score_distribution.png

![alt text](<../outputs/XGBoost  预测概率分布图.png>)

- **图 4-11 MLP 预测概率分布（按真实类别分组）**：figures/mlp_score_distribution.png
  MLP 在结构化特征（01）上的概率分布分离度较好，两类样本的预测概率重叠区域较小；在文本特征（02）上分布重叠明显，说明 TF-IDF 文本表示对 MLP 的区分能力有限；融合特征（03）介于两者之间。

![alt text](<../outputs/MLP  预测概率分布图.png>)

- **图 4-12 MLP-SBERT 预测概率分布（按真实类别分组）**：figures/mlp_sbert_score_distribution.png
  MLP-SBERT 在 SBERT 融合特征（03 SBERT）上的概率分布分离度优于 TF-IDF 融合，体现了预训练语义表示对神经网络分类的增益。SBERT 文本特征（02 SBERT）的分布重叠仍较明显，与结构化信息融合后区分能力显著提升。

![alt text](<../outputs/MLP-SBERT  预测概率分布图.png>)

### 4.3 结果分析与业务解读

#### 4.3.1 模型整体表现对比

本实验在三套特征方案上对比了 **Logistic Regression**、**XGBoost** 与 **MLP**（含 SBERT 扩展）三类模型，核心发现如下：

| 对比维度           | Logistic Regression        | XGBoost                            | MLP (TF-IDF / SBERT)                 |
| ------------------ | -------------------------- | ---------------------------------- | ------------------------------------ |
| **最佳 F1(1)**     | 0.769（01 结构化）         | **0.833**（01 结构化）             | 0.720（01 结构化）                   |
| **最佳 AUC**       | 0.971（01 结构化）         | **0.979**（01 结构化）             | 0.912（01 结构化）                   |
| **文本特征适应性** | 较弱（F1=0.111）           | 较好（F1=0.424）                   | 较弱（TF-IDF: 0.381 / SBERT: 0.273） |
| **融合特征表现**   | 提升有限（F1=0.333）       | 接近最优（F1=0.818）               | TF-IDF: 0.353 / **SBERT: 0.583**     |
| **SBERT 效果**     | —（未测试）                | —（未测试）                        | 融合 F1 从 0.353→0.583，提升 **65%** |
| **可解释性**       | 强（系数直接反映特征影响） | 中等（需借助特征重要性图辅助解释） | 弱（黑盒模型）                       |

**结论**：

1. `XGBoost` 在所有特征方案上均优于其他模型，尤其在**文本与融合特征**下优势最为显著（F1=0.833）。
2. `MLP` 在使用 **SBERT 融合特征**时表现显著优于 TF-IDF 融合（F1 从 0.353 提升至 0.583），证明神经网络能更好地利用稠密的语义向量表示。
3. 受限于小样本量（~210 条），MLP 整体弱于 XGBoost，但 SBERT 带来的改进表明：在数据充足的场景下，深度模型+预训练表示的组合具有更大潜力。

#### 4.3.2 特征方案效果分析

| 特征方案     | 信息来源    | Logistic F1 | XGBoost F1 | MLP F1 (TF-IDF) | MLP F1 (SBERT) |
| ------------ | ----------- | ----------: | ---------: | --------------: | -------------: |
| **01**       | 结构化字段  |       0.769 |  **0.833** |           0.720 |          0.720 |
| **02**       | TF-IDF      |       0.111 |      0.424 |           0.381 |              — |
| **02-SBERT** | SBERT 文本  |           — |          — |               — |          0.273 |
| **03**       | TF-IDF 融合 |       0.333 |      0.818 |           0.353 |              — |
| **03-SBERT** | SBERT 融合  |           — |          — |               — |      **0.583** |

**关键洞察**：

1. **结构化特征是核心驱动力**：无论模型类型，01 方案始终最优，说明房源的静态结构属性（价格、评分、房间数等）对 RevPAR 预测至关重要。
2. **文本特征单独使用价值有限**：文本嵌入在缺乏结构化信息时难以独立支撑预测，但作为补充特征仍有潜力。
3. **融合需配合非线性模型**：线性模型对高维融合特征容易出现"信号稀释"，而 XGBoost 和 MLP 能更好地利用多模态信息。
4. **SBERT 显著提升 MLP 融合效果**：MLP 在 SBERT 融合特征上 F1 达到 0.583，比 TF-IDF 融合的 0.353 提升约 **65%**，证明预训练语言模型的语义表示更适合深度学习模型。

#### 4.3.3 过拟合与欠拟合诊断

| 模型     | 特征方案    | 验证集 F1 | 测试集 F1 | 诊断结论                                                                |
| -------- | ----------- | --------: | --------: | ----------------------------------------------------------------------- |
| Logistic | 01          |     1.000 |     0.769 | 验证集过高，测试集下降明显，存在**轻微过拟合**（小样本 + 阈值调优敏感） |
| Logistic | 02          |     0.444 |     0.111 | 验证/测试均低，属于**欠拟合**（线性模型对文本表示能力不足）             |
| Logistic | 03          |     0.818 |     0.333 | 验证 → 测试降幅较大，存在**过拟合**（高维特征 + 小样本）                |
| XGBoost  | 01          |     0.952 |     0.833 | 验证/测试均高且差距可控，**拟合适中**                                   |
| XGBoost  | 02          |     0.483 |     0.424 | 验证/测试接近，**欠拟合**（文本信号不足）                               |
| XGBoost  | 03          |     0.900 |     0.818 | 验证/测试均高，**拟合良好**                                             |
| MLP      | 01          |         — |     0.720 | 结构化特征表现稳定，早停机制有效控制过拟合                              |
| MLP      | 02 (TF-IDF) |         — |     0.381 | 文本特征效果有限，但优于 Logistic，**欠拟合**                           |
| MLP      | 03 (TF-IDF) |         — |     0.353 | TF-IDF 融合效果一般，低于 XGBoost                                       |
| MLP      | 02 (SBERT)  |         — |     0.273 | SBERT 文本单独使用效果弱，**欠拟合**                                    |
| MLP      | 03 (SBERT)  |         — |     0.583 | SBERT 融合显著优于 TF-IDF，Dropout+早停有效，**拟合适中**               |

**诊断小结**：

- Logistic Regression 在小样本高维场景下易**过拟合**或**欠拟合**，泛化能力受限。
- XGBoost 通过集成学习与正则化（`subsample`、`colsample_bytree`）有效控制了过拟合风险，在 01/03 上均表现稳健。
- MLP 在 TF-IDF 特征上表现平平，但 **SBERT 融合特征**下 F1 达到 0.583，表明神经网络能更好地利用预训练语义表示。
- 文本特征（02）在所有模型下均呈**欠拟合**态势，单独文本信息不足以支撑有效预测。

#### 4.3.4 重要特征解读与高 RevPAR 房源画像

根据 **图 4-7/4-8** 的特征排序结果，结合业务语义，可提炼出"高 RevPAR 房源"的典型特征画像：

| 特征类别     | 高 RevPAR 房源特征                                                     | 低 RevPAR 房源特征                 |
| ------------ | ---------------------------------------------------------------------- | ---------------------------------- |
| **房源热度** | 优质房源因需求旺、易满房，开放预定比率自然偏低                         | 需求弱的房源需长期高开放率吸引租客 |
| **价格定位** | 定价处于区域中上水平，但不过高（避免低入住率）                         | 定价过低或过高，偏离市场均衡       |
| **房型规模** | 较多卧室/床位（适合家庭或团体），空间利用率高                          | 单间或小户型，承载量有限           |
| **评分表现** | 综合评分高                                                             | 评分一般或存在明显短板             |
| **地理位置** | 位于热门旅游区或交通便利区域（如市中心、景点周边）                     | 偏远或交通不便                     |
| **设施配置** | 提供必需设施（WiFi、空调、厨房等）及差异化设施（停车位、阳台、景观等） | 设施单一，缺乏亮点                 |

#### 4.3.5 业务建议

基于上述分析，针对不同角色提出以下可操作建议：

**对房东（Host）**：

1. **优化开放预定策略**：控制开放预定周期，避免长期全开放，结合需求波动调整开放率，提升房源 “稀缺感”
2. **优化定价策略**：参考同区域、同房型的价格分布，将日均价格定位在中位数偏上，兼顾入住率与单价收益。
3. **提升评分短板**：重点关注清洁度与位置便利性评分，及时响应房客反馈，保持 4.8 分以上的综合评分。
4. **完善设施与描述**：在房源描述中突出差异化卖点（如景观、交通、周边设施），并确保实际设施与描述一致。

**对平台（Airbnb）**：

1. **个性化推荐**：基于本模型预测的 RevPAR 潜力，向房东推送定价建议或优化提示，提升整体供给质量。
2. **新房东扶持**：对新上线房源，可参考模型预测结果，发掘优质房源，扶持新房东。
3. **文本信息挖掘**：后续可引入更强的 NLP 模型（如 BERT）对评论/描述文本建模，挖掘更细粒度的用户偏好与房源卖点。

**对房客（Guest）**：

1. **选房参考**：优先关注 高评分、价格处于区域中位数附近的房源，性价比更优。
2. **避免极端定价**：过低价格可能意味着设施缺失或评分较差，过高价格未必带来等比例的体验提升。

---

## 5. 嵌入空间可视化与文本模式挖掘

### 5.1 嵌入空间可视化设计

#### 5.1.1 降维方法选择与参数设置

为探究不同模态特征的类别可分性，本实验对三套特征数据集（01 结构化、02 文本、03 融合）分别应用三种经典降维算法，将高维特征映射至 2D 空间进行可视化分析：

- **PCA（主成分分析）**：线性降维方法，保留数据最大方差，参数设置 `n_components=2`，`random_state=42`。
- **t-SNE（t-分布邻域嵌入）**：非线性降维方法，擅长捕捉局部结构，参数设置 `n_components=2`，`perplexity=30`，`max_iter=1000`，`init="pca"`，`random_state=42`。
- **UMAP（均匀流形近似与投影）**：兼顾局部与全局结构的非线性降维方法，参数设置 `n_components=2`，`random_state=42`（需安装 `umap-learn` 库）。

降维流程通过 `dimensionality_reduction.py` 与 `fused_feature_dim_reduction.py` 协同实现：前者负责加载 `train_01.csv`、`train_02.csv` 并执行降维；后者专门处理 `train_03.csv` 融合特征，强制路径为 Path 类型避免兼容错误，自动筛选数值特征，处理无穷值与缺失值（中位数插补），标准化后执行三种降维，输出嵌入结果 CSV 与 2D 可视化图至 `outputs` 目录；后续通过 `embedding_visualization.py` 加载嵌入文件，按类别（高/非高 RevPAR）上色，生成类别分布可视化图。

#### 5.1.2 可视化评估指标

- **分离度定性评估**：观察两类样本在 2D 空间中的聚集程度，是否形成明显聚类，无严重重叠。
- **视觉区分度**：通过颜色区分（蓝色=高 RevPAR 0，红色=非高 RevPAR 1），判断人工能否快速识别两类边界。
- **模态对比**：横向对比三套特征在同一降维方法下的分离效果，纵向对比同一特征在不同降维方法下的表现。

### 5.2 嵌入空间可视化结果与分析

#### 5.2.1 结构化特征（01）降维可视化

基于 `train_01.csv` 的结构化特征（房源规模、价格、评分等），通过三种降维方法得到以下类别分布结果：

- **图 5-1 PCA 结构化特征 2D 嵌入（类别分布）**：
  ![alt text](../outputs/pca_category_distribution.png)
  图注：PCA 作为线性降维方法，能保留结构化特征的核心方差信息。从图中可见，高 RevPAR 样本（蓝色）在空间中呈现一定聚集趋势，主要集中在特定区域，与非高 RevPAR 样本（红色）形成部分分离，但仍有明显重叠区域，说明结构化特征中存在线性可分的类别信号，但区分度有限。

- **图 5-2 t-SNE 结构化特征 2D 嵌入（类别分布）**：
  ![alt text](../outputs/tsne_category_distribution.png)
  图注：t-SNE 擅长捕捉局部结构，降维后两类样本的聚集性显著增强。蓝色高 RevPAR 样本形成多个紧凑聚类，红色样本虽仍有分散，但与蓝色聚类的重叠区域大幅减少，分离效果明显优于 PCA，体现了结构化特征中存在非线性的局部类别模式。

- **图 5-3 UMAP 结构化特征 2D 嵌入（类别分布）**：
  ![alt text](../outputs/umap_category_distribution.png)
  图注：UMAP 兼顾局部聚集与全局分布，降维后两类样本实现最优分离。蓝色样本形成边界清晰的核心聚类，红色样本围绕其分布且无大规模交叉，能精准反映结构化特征中与 RevPAR 相关的类别差异，是三种降维方法中最适配结构化特征的选择。

#### 5.2.2 文本特征（02）降维可视化

基于 `train_02.csv` 的文本特征（房源标题+设施列表的 TF-IDF 嵌入），降维后的类别分布如下：

- **图 5-4 PCA 文本特征 2D 嵌入（类别分布）**：
  ![alt text](../outputs/pca_2d.png)
  图注：PCA 对文本高维稀疏特征的线性降维效果较差，两类样本完全交织在一起，红色点分散在蓝色点中无明显聚集趋势，无法通过线性边界区分类别，说明文本特征的类别信号难以通过线性变换提取。

- **图 5-5 t-SNE 文本特征 2D 嵌入（类别分布）**：
  ![alt text](../outputs/tsne_2d.png)
  图注：t-SNE 虽能挖掘文本特征的局部关联，但受限于文本信号的弱区分性，仅使少量高 RevPAR 样本形成微小聚类，大部分红色点仍与蓝色点重叠，未能实现有效分离，反映单一文本特征的类别区分能力较弱。

- **图 5-6 UMAP 文本特征 2D 嵌入（类别分布）**：
  ![alt text](../outputs/umap_2d.png)
  图注：UMAP 对文本特征的分离效果略优于前两种方法，部分红色样本形成稀疏聚类，但整体仍无清晰边界，蓝色样本的分散程度较高，说明仅依赖文本特征难以稳定区分高/非高 RevPAR 房源，文本信息的类别指示性较弱。

#### 5.2.3 融合特征（03）降维可视化

基于 `train_03.csv` 的融合特征（结构化特征+文本特征拼接），通过 `fused_feature_dim_reduction.py` 执行降维后，类别分布如下：

- **图 5-7 PCA 融合特征 2D 嵌入（类别分布）**：
  ![alt text](../outputs/pca_fused_feature_dist.png)
  图注：PCA 降维后，融合特征继承了结构化特征的线性分离趋势，高 RevPAR 样本（蓝色）聚集性进一步增强，主要集中在空间中下部区域，与非高 RevPAR 样本（红色）的重叠区域较纯结构化特征大幅减少。结合 `pca_fused_feature_embedding.csv` 数据可知，两类样本在 PCA 维度 1 和维度 2 上的分布差异更显著，文本特征提供的互补信息增强了线性可分信号，但未完全消除重叠。

- **图 5-8 t-SNE 融合特征 2D 嵌入（类别分布）**：
  ![alt text](../outputs/tsne_fused_feature_dist.png)
  图注：t-SNE 降维后，融合特征实现最优分离效果。蓝色高 RevPAR 样本形成紧凑且边界清晰的核心聚类，红色样本分散程度显著降低，无明显交叉重叠，与 `tsne_fused_feature_embedding.csv` 中嵌入数据的聚类分布一致。这体现了结构化特征的核心预测信号与文本特征的局部补充信号形成协同，非线性模型可充分利用这种多模态关联提升类别区分能力。

- **图 5-9 UMAP 融合特征 2D 嵌入（类别分布）**：
  ![alt text](../outputs/umap_fused_feature_dist.png)
  图注：UMAP 降维兼顾局部聚集与全局分布，蓝色高 RevPAR 样本形成高度集中的聚类，红色样本呈环绕式分布，两类边界清晰且无孤立异常点。结合 `umap_fused_feature_embedding.csv` 数据统计，两类样本在 UMAP 二维空间中的类内距离更小、类间距离更大，验证了多模态特征融合能有效增强类别区分性，为后续模型提供更优质的特征表示空间。

##### 5.2.3.1 融合特征嵌入空间量化分析

| method | dist_between_centers | compactness_ratio |
| ------ | -------------------- | ----------------- |
| PCA    | 2.266305             | 0.838241          |
| t-SNE  | 3.805517             | 0.763595          |
| UMAP   | 0.903336             | 0.893298          |

###### PCA 嵌入空间分析

- **线性可分性**：PCA 作为线性方法，类别间中心距离为 2.266，表明两类样本在 PCA 空间中**存在明确的线性分离趋势**，但类别 0 紧密度（2.311）高于类别 1（1.937），说明非高 RevPAR 房源线性特征分布更分散
- **方差解释**：类别 1/类别 0 紧密度比为 0.838，高 RevPAR 房源在 PCA 空间中聚集性更好，体现其线性特征模式更统一
- **业务意义**：高 RevPAR 房源中心点[0.968 1.391]与非高 RevPAR[-0.327 -0.47]呈反向分布，说明核心线性特征（价格、评分、设施数量）与 RevPAR 呈正相关

###### t-SNE 嵌入空间分析

- **局部结构保留**：t-SNE 的类别间距离（3.806）为三种方法中最大，说明**局部聚类分离效果最优**，高 RevPAR 房源中心点[1.336 -2.879]与非高 RevPAR[-0.648 0.369]完全分离
- **非线性模式**：类别 1 紧密度（7.562）远低于类别 0（9.903），紧密度比 0.764 为三者最低，表明高 RevPAR 房源在局部特征空间中分布更紧凑，非线性特征模式更显著
- **计算效率**：t-SNE 虽分离效果最优，但紧密度绝对值（类别 0=9.903）远高于其他方法，说明样本分布范围大，计算成本更高

###### UMAP 嵌入空间分析

- **全局结构**：UMAP 类别间距离（0.903）最小，但紧密度比值（0.893）最高，说明**在保持全局分布紧凑的同时，两类样本内部一致性最优**
- **分离效果**：类别 0 中心点[3.483 1.95]与类别 1[3.068 1.148]空间位置接近但边界清晰，体现 UMAP 对全局与局部结构的平衡能力
- **实用性**：类别紧密度绝对值（类别 0=1.598、类别 1=1.427）远低于 t-SNE，计算效率更高，且紧密度比接近 1，适合大规模数据的稳定分析

#### 5.2.4 可视化结果总结

| 特征方案  | PCA 分离度 | t-SNE 分离度 | UMAP 分离度 | 最优降维方法 |
| --------- | ---------- | ------------ | ----------- | ------------ |
| 01 结构化 | 中等       | 良好         | 优秀        | UMAP         |
| 02 文本   | 极差       | 较差         | 一般        | UMAP         |
| 03 融合   | 良好       | 优秀         | 极佳        | UMAP         |

核心结论：

1. 结构化特征是类别区分的核心，非线性降维（UMAP > t-SNE > PCA）对其分离效果更优；
2. 文本特征单独使用时类别分离度极弱，需依赖非线性降维才能捕捉微弱模式；
3. 融合特征在所有降维方法下均优于单一模态，UMAP 降维后能实现近完全分离，验证了多模态信息的互补价值；
4. 融合特征的降维流程通过专门脚本实现，解决了路径兼容问题，输出的嵌入 CSV 文件可用于后续模型优化与特征验证。

### 5.3 顶级房源文案模式挖掘

#### 5.3.1 挖掘流程与方法

通过 `top_listing_text_mining.py` 对高 RevPAR 房源（`y=1`）的 `listing_name` 与 `amenities` 文本进行深度挖掘，流程如下：

1. 数据加载与筛选：加载 `data/London_listing_target.csv`，筛选 `y=1` 的高 RevPAR 房源；
2. 文本预处理：合并 `listing_name` 与 `amenities` 为统一文本，小写化、去除标点、过滤英文停用词；
3. 词频统计：统计预处理后文本的词频，提取 Top20 高频词；
4. 关键词提取：使用 TF-IDF 算法计算词权重，提取 Top20 核心关键词；
5. LLM 模式归纳：调用 `facebook/bart-large-cnn` 模型，对文本样本进行摘要总结，归纳常见主题模式；
6. 报告生成：将词频统计、关键词、LLM 摘要整理为 Word 报告 `outputs/top_listing_analysis.docx`。

#### 5.3.2 挖掘结果与分析

##### 5.3.2.1 词频统计结果

**表 5-1 高 RevPAR 房源文本 Top20 高频词**
| 排名 | 词汇 | 频率 | 排名 | 词汇 | 频率 |
|------|--------------------|------|------|--------------------|------|
| 1 | monoxide | 61 | 11 | dropoff | 33 |
| 2 | parking | 60 | 12 | rack | 33 |
| 3 | alarmcarbon | 56 | 13 | basicsdishes | 31 |
| 4 | pillows | 46 | 14 | reading | 27 |
| 5 | linensextra | 45 | 15 | allowedlong | 25 |
| 6 | water | 45 | 16 | hair | 20 |
| 7 | term | 39 | 17 | extinguisherfirst | 19 |
| 8 | stays | 39 | 18 | dryercleaning | 19 |
| 9 | aid | 35 | 19 | n | 18 |
| 10 | alarmfire | 33 | 20 | playtravel | 18 |

分析：高频词中，`parking`（停车位）、`alarmcarbon`（碳 monoxide 报警器）、`alarmfire`（火灾报警器）、`extinguisherfirst`（灭火器+急救包）等安全与实用设施词汇占比极高，说明高 RevPAR 房源重视基础保障；`pillows`（枕头）、`linensextra`（额外床品）、`dryercleaning`（干洗机）体现对居住舒适度的关注；`allowedlong`（允许长期入住）反映运营策略灵活性。

##### 5.3.2.2 TF-IDF 关键词提取结果

**表 5-2 高 RevPAR 房源文本 Top20 TF-IDF 关键词**
| 排名 | 关键词 | TF-IDF 分数 | 排名 | 关键词 | TF-IDF 分数 |
|------|----------------------|-------------|------|----------------------|-------------|
| 1 | parking | 0.0562 | 11 | term | 0.0430 |
| 2 | monoxide | 0.0548 | 12 | dropoff | 0.0414 |
| 3 | alarmcarbon | 0.0543 | 13 | hair | 0.0399 |
| 4 | pillows | 0.0467 | 14 | rack | 0.0388 |
| 5 | linensextra | 0.0462 | 15 | allowedlong | 0.0347 |
| 6 | water | 0.0455 | 16 | extinguisherfirst | 0.0346 |
| 7 | alarmfire | 0.0448 | 17 | reading | 0.0341 |
| 8 | aid | 0.0447 | 18 | flat | 0.0331 |
| 9 | basicsdishes | 0.0443 | 19 | allowed | 0.0315 |
| 10 | stays | 0.0430 | 20 | silverwareheatingcooking | 0.0308 |

分析：TF-IDF 关键词与高频词高度一致，但 `parking`、`monoxide`、`alarmcarbon` 等词汇的权重更高，说明这些词汇在高 RevPAR 房源中不仅出现频繁，且具有强区分度（低 RevPAR 房源中出现较少）；`silverwareheatingcooking`（餐具+供暖+烹饪设施）、`basicsdishes`（基础餐具）等关键词体现高 RevPAR 房源对“生活便利性”的重视，满足租客核心需求。

##### 5.3.2.3 LLM 文本模式归纳摘要

基于 `facebook/bart-large-cnn` 模型的摘要结果（来自 `top_listing_analysis.docx`）：
"Based on AirROI's comprehensive Airbnb dataset, the high-RevPAR listings consistently emphasize practicality, safety, and comfort as core themes. Scenery and views are less frequently highlighted compared to essential amenities and accessibility. Transportation convenience is indirectly reflected through mentions of parking, a key feature for travelers with vehicles, enhancing accessibility in urban areas like London. Family-oriented elements are evident in extra linens, pillows, and flexible long-stay policies, catering to groups and extended stays. Luxury and modern comforts are subtle but present in amenities like dry cleaning facilities and well-equipped kitchens with silverware and heating. Safety is a top priority, with prominent mentions of carbon monoxide alarms, fire alarms, and first aid kits, building trust with guests. Practical amenities such as water access, basic dishes, and hair care facilities ensure daily comfort, directly boosting guest satisfaction and positive reviews. These patterns collectively drive high RevPAR by balancing essential needs with thoughtful extras, reducing guest friction and encouraging longer stays and repeat bookings, ultimately maximizing ROI for hosts."

摘要解读：高 RevPAR 房源文案的核心模式可归纳为四类：

1. **安全保障优先**：突出各类安全设施（报警器、急救包），建立租客信任；
2. **实用设施齐全**：聚焦停车、餐具、供暖等高频使用的基础设施，满足日常需求；
3. **居住舒适度提升**：通过额外床品、干洗机等细节提升体验；
4. **运营策略灵活**：支持长期入住，扩大客群覆盖（家庭、长期租客）。

### 5.4 代价-收益分析

本节从“模型性能–特征复杂度”与“工程实现代价–业务价值”两个维度，综合评估三套特征方案（01 结构化、02 文本、03 融合）和三类模型（Logistic、XGBoost、MLP/MLP‑SBERT）的性价比。

#### 5.4.1 模型性能与特征复杂度的权衡

1. **01 结构化特征：低复杂度下的高收益**

   - 在 01 特征上，XGBoost 测试集 F1(1)=0.833、AUC=0.979，是本项目整体表现最好的组合；Logistic F1(1)=0.769、AUC=0.971，MLP F1(1)=0.720、AUC=0.912，也都达到了较高水平；
   - 这一方案仅依赖少量结构化字段和适度的特征工程（缺失值处理、标准化、评分 PCA 合并等），工程复杂度和算力需求都较低，却已经可以在不平衡数据上稳定识别高 RevPAR 房源；
   - 从“单位工程投入带来的性能提升”角度看，01+XGBoost 组合具有最高的性价比，可视为真实业务中最优先部署的基线方案。

2. **02 文本特征：中高复杂度下的有限收益**

   - 仅使用 TF‑IDF 文本特征时（02），Logistic 的 F1(1)=0.111、AUC=0.578，几乎无法有效识别高 RevPAR 房源；XGBoost 的 F1(1)=0.424、AUC=0.618，MLP 的 F1(1)=0.381、AUC=0.588，性能明显弱于结构化特征；
   - 在 SBERT 文本嵌入上，MLP‑SBERT 的文本方案 F1(1)=0.273、AUC=0.591，仍难以超越结构化基线，说明在当前样本规模下，单靠标题与设施文本很难稳定刻画“高 RevPAR”模式；
   - 结合嵌入可视化结果，文本特征确实在语义空间中提供了一定区分度，但在样本较少、标签噪声存在的前提下，其边际性能贡献有限，更适合作为辅助信息而非单独决策依据。

3. **03 融合特征：性能略有提升但不稳定**

   - 对于标准特征，03 融合方案在 XGBoost 上的 F1(1)=0.818、AUC=0.952，略低于 01 结构化方案（0.833/0.979），说明简单拼接 TF‑IDF 文本在当前数据规模下并未带来确定性的性能收益；
   - 在 MLP 上，03 融合（TF‑IDF）表现甚至差于仅结构化方案（F1 从 0.720 降至 0.353），反映出在小样本场景下，简单增加特征维度反而加剧了过拟合风险；
   - 对于 SBERT，多模态融合（03 SBERT）使 MLP‑SBERT 的 F1(1) 从 0.273 提升到 0.583、AUC=0.818，相比“纯文本 SBERT”有明显收益，但整体仍未超过 01+XGBoost 组合；
   - 综合来看，03 融合在“深度文本表示 + 神经网络”配置下可以带来局部增益，但在整体性能上只是接近而未超越结构化强基线，其收益更多体现在提供一种可扩展的多模态建模路径。

#### 5.4.2 不同特征方案的工程与维护代价

1. **01 结构化特征：工程成本最低**

   - 主要工作集中在缺失值处理、异常值修正、数值标准化、评分 PCA 合并以及少量类别编码，数据处理链路清晰、依赖库简单（pandas、scikit‑learn 为主）；
   - 计算开销主要来自标准化与 PCA，整体在单机环境下可以快速完成，适合集成到定期离线批处理任务中；
   - 结构化特征对数据更新的敏感度较低，只要保持字段定义稳定，模型重训与上线流程较为可控，长期维护成本最低。

2. **02 文本特征：预处理和建模链路较长**

   - TF‑IDF 方案需要完成分词、停用词过滤、ngram 选择、特征截断等一系列预处理步骤，并配合 TruncatedSVD 与 StandardScaler 做降维和标准化，调参空间大、试错成本高；
   - SBERT 方案在此基础上还引入预训练语言模型，涉及模型下载、显存占用、推理时间等问题，对运行环境和部署形态提出了更高要求；
   - 文本特征对语料分布变化较为敏感，Airbnb 平台的文案风格若随时间变化，TF‑IDF 词表和 SBERT 表示都需要重新校准，长期维护成本明显高于结构化方案。

3. **03 融合特征：多模态流水线的额外开销**

   - 融合方案需要保证 01/02 两套特征在样本顺序和标签上的严格对齐，并通过特征拼接、降维、可视化等步骤构造最终输入，增加了数据一致性校验和调试工作量；
   - 相关脚本（如 `feature_merging.py`、`fused_feature_dim_reduction.py`、`embedding_visualization.py`）需要同时兼顾路径配置、文件命名规范和不同运行环境，对工程规范性要求更高；
   - 一旦业务侧决定增加新的模态（例如评论文本、地理 POI 等），多模态流水线需要整体调整，对开发团队的工程能力和测试投入提出更多要求。

#### 5.4.3 综合性价比结论与业务建议

综合模型表现与工程代价，可以给出如下结论与建议：

1. **最优综合性价比方案**

   - 在当前样本规模和字段条件下，01 结构化特征 + XGBoost 组合以较低工程复杂度换来了最高的预测性能，是“上线一个稳定可用模型”的首选；
   - 若更强调可解释性和运营洞察，可在结构化特征上优先选择 Logistic Regression，通过系数和特征重要性分析为房东和平台提供清晰的“高 RevPAR 画像”。

2. **文本与多模态特征的定位**

   - 在现有数据规模下，文本与多模态特征在纯指标上的收益有限，更适合作为“锦上添花”的模块：用于挖掘文案模式、解释高收益房源的卖点，而不是单纯追求模型精度；
   - 对于资源有限或中小规模业务场景，可以优先部署 01 结构化方案，将文本挖掘限制在离线分析层面（词频/关键词+少量可视化），暂不强制引入 SBERT 和复杂多模态流水线；
   - 对于数据量和算力都较充足的平台，可以在 01+XGBoost 的基线之上，按需叠加 03 融合或 03 SBERT 方案，用于进一步挖掘文本信号，并为后续引入评论文本、动态画像等扩展预留空间。

3. **后续迭代的优先级建议**

   - 在“额外投入一定工程人力”的前提下，优先级应依次考虑：补充更丰富的结构化特征（地理 POI、时序指标）＞ 优化不平衡处理和阈值调优 ＞ 在更大样本上重新评估文本/多模态方案；
   - 只有当样本规模显著扩大、文本数据源更加多样（增加评论、回复等），并且业务侧对“文案优化建议”和“差异化推荐理由”有强需求时，才值得大规模投入多模态与 SBERT 相关的工程建设。

## 6. 结论与不足

### 6.1 主要结论

- 用 3–5 条 bullet point，总结本项目的关键发现：
  - 如：哪些因素对 RevPAR 影响最大？
  - 不同城市/房型是否存在显著差异？
  - 最佳模型及其大致预测精度。

### 6.2 不足与改进方向

- 数据层面的不足：
  - 如评分偏高、缺乏取消订单数据、缺失某些关键特征等。
- 方法层面的不足：
  - 特征工程不够深入、文本/地理信息未充分利用等。
- 未来可以尝试的改进方向：
  - 使用更多高级模型、引入时间序列/因果分析、引入 NLP 对评论文本建模等。

#### 6.2.1 数据层面的不足

| 不足类型         | 具体表现                                                                         | 对实验的影响                                                  |
| ---------------- | -------------------------------------------------------------------------------- | ------------------------------------------------------------- |
| **样本量偏小**   | 训练集仅约 210 条，验证/测试集各约 45 条                                         | 模型泛化能力受限，验证集 → 测试集性能波动较大，过拟合风险较高 |
| **类别不平衡**   | 正负类比例约 1:3，少数类（高 RevPAR）样本有限                                    | 即使使用加权和阈值调优，少数类的 Precision/Recall 仍存在权衡  |
| **评分分布偏高** | Airbnb 评分普遍集中在 4.5–5.0 区间，区分度不足                                   | 评分类特征的预测贡献可能被低估，难以有效区分中等与优质房源    |
| **时序信息缺失** | 仅使用静态快照数据，未纳入价格/入住率的时间序列变化                              | 无法捕捉季节性波动、节假日效应等动态因素对 RevPAR 的影响      |
| **地理粒度粗糙** | 缺乏精细的地理编码（如 POI 密度、地铁距离等），未使用 `neighbourhood` 等类别字段 | 地理位置对房源收益的影响未能充分量化                          |

#### 6.2.2 方法层面的不足

| 不足类型                | 具体表现                                                             | 对实验的影响                            |
| ----------------------- | -------------------------------------------------------------------- | --------------------------------------- |
| **SBERT 仅在 MLP 测试** | 引入了 Sentence-BERT，但仅与 MLP 配合测试，未应用于 Logistic/XGBoost | 无法全面评估 SBERT 对传统模型的提升效果 |
| **特征工程深度有限**    | 未构建交叉特征、聚合特征（如区域均价、房东历史表现等）               | 可能遗漏重要的特征交互信号              |
| **MLP 调参有限**        | MLP 采用手动调参而非系统化搜索                                       | 可能未达到 MLP 的最优性能               |
| **超参搜索空间有限**    | 网格搜索参数组合较少，未使用贝叶斯优化或随机搜索                     | 可能未找到全局最优超参数                |
| **阈值调优依赖验证集**  | 阈值在验证集上选取，测试集仅做最终评估                               | 验证集样本量小，阈值可能存在过拟合风险  |

#### 6.2.3 未来改进方向

针对上述不足，提出以下改进思路：

**数据增强与扩展**：

1. **扩大样本量**：纳入更多城市或更长时间范围的数据，提升模型泛化能力。
2. **引入时序特征**：利用 Calendar 表构建价格/入住率的滑动窗口统计量（如近 7 天均价、周末溢价率等），捕捉动态趋势。
3. **细化地理信息**：引入 POI 数据（景点、地铁站、商圈距离）或使用地理嵌入（如 Geohash、H3）提升空间建模能力。

**特征与表示优化**：

4. **升级文本表示**：使用预训练语言模型（BERT、Sentence-BERT）对房源描述和评论文本编码，提升语义捕捉能力。
5. **构建交叉/聚合特征**：如 `价格 × 评分`、`区域均价排名`、`房东累计好评数` 等，挖掘特征交互。
6. **特征选择与降维**：对高维融合特征使用 L1 正则化、RFE 或 PCA，减少噪声干扰。

**模型与调参改进**：

7. **尝试更多模型**：LightGBM、CatBoost（对类别特征友好）、TabNet（深度表格模型）等。
8. **集成学习**：Stacking 或 Blending 融合多模型预测，提升稳定性。
9. **贝叶斯超参优化**：使用 Optuna 或 Hyperopt 进行更高效的超参搜索。
10. **交叉验证阈值选择**：在 5 折 CV 中分别选取阈值并取均值，降低阈值过拟合风险。

**业务与可解释性**：

11. **引入因果推断**：使用倾向得分匹配或 DoWhy 分析特定因素如 Superhost 对 RevPAR 的因果效应。
12. **模型可解释性**：引入 SHAP 或 LIME 对 XGBoost 预测进行局部解释，辅助业务决策。

---

## 7. 小组协作与个人收获

### 7.1 分工与协作情况（GitHub/Git）

我们小组在 GitHub 上主要采用 **branch + pull request** 的方式进行协作开发。整体流程是：先确定每位成员负责的模块或任务，将功能拆分为若干小目标；每位成员在本地从主分支拉取最新代码后，新建各自的功能分支进行开发与实验记录整理。开发过程中尽量保持提交粒度清晰（一次提交对应一个小功能或一次实验改动），并在提交信息中说明改动内容，便于组内追踪与回溯。

当某项功能或阶段性内容完成后，成员会将功能分支推送到远端，并通过 Pull Request 发起合并请求。在 PR 中简要描述实现内容、涉及文件及可能的注意事项；其他成员会进行代码检查与结果核对，必要时提出修改意见并在同一 PR 下迭代更新。确认无误后再由负责成员将其合并到主分支，从而保证主分支始终保持可运行、可复现的状态。

在协作沟通方面，我们通过组内讨论明确接口与数据格式，尽量减少多人同时修改同一文件的情况；若出现分歧，会先在本地验证或对比实验结果后再统一方案。合并前统一进行 `pull` 更新并解决潜在冲突，确保代码与实验材料同步，提升协作效率并降低 git 冲突发生概率。

以下是我们Github/Git部分的截图内容，反映了我们团队的协作过程：
![alt text](../outputs/9c22a66f-b696-44a9-a94e-29bf5840b93c.png)

### 7.2 个人收获（每人 3–5 句话）


- 陈彦博： 本次实验我主要完成对结构化特征、文本特征、融合特征的降维和分析，嵌入空间可视化与文本模式挖掘，通过本次实验，我深刻认识到，结构化特征往往比文本特征更具预测效力，而简单的特征拼接未必带来性能提升，反而可能因过拟合导致效果下降。可视化分析让我直观理解了不同模态特征的类别区分能力，并认识到选择合适的降维方法（如UMAP）对揭示数据结构至关重要。这次实验的团队合作方式也让我感到一份团结，大家一起齐心协力完成任务的决心是最可贵的。
- 胡一泓： 本次实验让我掌握了类别不平衡问题的处理方法如：样本加权 + 阈值调优，理解了 F1 等指标在不平衡场景下的重要性。通过 Logistic 与 XGBoost 的对比，我直观感受到非线性模型在高维特征下的优势。同时，通过小组 git 的合作模式，学习到了 github 以及 git 的使用，并体会到团队项目中沟通交流的重要性以及协作下的高效，有助于我日后学习工作上的组间合作。
- 徐治勋： 本次项目从原始 Airbnb 数据表的清洗与分析入手，让我系统实践了缺失值处理、异常值识别以及类别重编码等预处理流程；在三套特征向量的选择与构造过程中，我学会了如何在业务含义和统计指标之间做权衡，逐步筛选出兼顾解释性与模型效果的特征组合；在多次调试脚本、对齐 Train/Val/Test 数据的过程中，我也意识到前期规范好数据流程、文件命名和随机种子设置的重要性；同时与小组成员们在github上的合作也对日后的学习实践有很大帮助。
- 陶睿： 本次实验我主要完成了两个 MLP 模型（标准 MLP 与 SBERT-MLP）的训练与评估，以及 SBERT 数据集的预处理与生成工作。在实验过程中，我深入学习了 SBERT 的相关知识，掌握了调节神经网络超参数（如学习率、神经元数量、Dropout）的技巧，并通过增加类别权重平衡成功解决了 Text 文本特征下模型 F1 值为 0 的问题。此外，通过 Git/GitHub 进行团队协作，我深刻体会到了版本控制对于多人开发的重要性，分支管理和 Pull Request 机制不仅避免了代码冲突，也让我们的合作更加高效顺畅。

---

## 8. 附录

- 主要代码结构说明  
  - `src/`：包含可复现的训练与评估脚本，其中 `main.py` 为命令行入口，`utils.py` 封装了数据加载、模型训练、评估与可视化等核心函数。  
  - `data/`：存放原始房源表 `London_listing.csv`、打标后的 `London_listing_target.csv`，以及三套特征方案（01/02/03 与 SBERT 版本）的 Train/Val/Test 划分 CSV 文件。  
  - `notebooks/`：用于数据预处理、特征工程与模型原型实验的 Notebook 与辅助脚本，例如结构化/文本特征构造、降维与嵌入可视化等。  
  - `outputs/`：保存模型训练与分析过程中生成的各类图表和中间结果（相关系数热力图、降维结果、ROC 曲线、混淆矩阵、性能对比图等）。  
  - `reports/`：课程设计项目报告。  
  - `projects/`：课程给出的 7 个可选课题说明文档，当前项目对应 `project6_multimodal_representation.md`。  

- 关键函数 / 脚本说明  
  - `src/main.py`：项目主入口，一次性调用 Logistic Regression、XGBoost、MLP 与 MLP-SBERT 四类模型，对三套特征（含 SBERT 版本）进行训练、阈值调优与测试集评估，并在 `outputs/` 下生成对比图表。  
  - `src/utils.py`：实现数据集加载（`load_multimodal_splits*`）、模型训练函数（`train_Logistic_Regression`、`train_XGBoost`、`train_MLP`）、性能评估函数以及多种绘图函数（F1 对比柱状图、ROC 曲线、混淆矩阵、特征重要性排序图、预测概率分布图等）。  
  - `notebooks/data_preprocess_structuring.ipynb`：从 `London_listing.csv` 开始完成标签构造、Train/Val/Test 分层划分以及结构化特征（01 套特征）的清洗、变换与筛选，生成 `train_01/val_01/test_01`。  
  - `notebooks/data_preprocess_text.ipynb`：对 `listing_name` 和 `amenities` 进行清洗、TF‑IDF + SVD / SBERT + PCA 编码，生成 `train_02/val_02/test_02` 和 `train_02_sbert/val_02_sbert/test_02_sbert`。  
  - `notebooks/fused_feature_dim_reduction.ipynb` 与 `notebooks/dimensionality_reduction.py`：将结构化与文本特征进行拼接，构造 03 套融合特征，并对高维特征做 PCA / t‑SNE / UMAP 降维与可视化。  
  - `notebooks/embedding_visualization.ipynb` 与 `embedding_visualization.py`：对融合特征与 SBERT 嵌入进行二维 / 三维可视化，分析高 RevPAR 房源在嵌入空间中的分布形态。  
  - `notebooks/model_Logistic Regression.ipynb`、`model_XGBoost.ipynb`、`model_MLP.ipynb`、`model_MLP_SBERT.ipynb`：用于模型原型设计、超参数搜索与训练过程可视化，最终整理为脚本化流程集成在 `src/main.py` 中。  

- 运行项目的简要步骤  
  1. 安装依赖  
     - 在项目根目录下创建并激活 Python 环境（建议 Python 3.10+），执行：  
       `pip install -r requirements.txt`。  
  2. 准备数据  
     - 将从 AirROI Data Portal 下载的 `London_listing.csv` 放置到 `data/` 目录；  
     - 若从零开始复现数据处理流程，可依次运行 `notebooks/data_preprocess_structuring.ipynb` 与 `notebooks/data_preprocess_text.ipynb`，得到 `London_listing_target.csv` 以及 01/02/03 三套特征对应的 Train/Val/Test CSV 文件；  
     - 本仓库已提供处理好的 `train_01/val_01/test_01`、`train_02/val_02/test_02`、`train_03/val_03/test_03` 及其 SBERT 版本，可直接用于模型训练。  
  3. 训练与生成结果  
     - 在项目根目录执行：  
       `python src/main.py`  
       或显式指定数据目录：  
       `python src/main.py --data-dir ./data`；  
     - 运行结束后，终端中会输出 Logistic / XGBoost / MLP / MLP-SBERT 在不同特征方案上的性能对比表，同时在 `outputs/` 目录下生成对应的 ROC 曲线、混淆矩阵、F1 对比图、预测概率分布图及特征重要性排序图。  

- 额外图表与补充分析  
  - `outputs/numeric_corr_heatmap.png`：结构化数值特征与标签的相关系数热力图，用于支撑特征筛选与 PCA 降维设计。  
  - `outputs/pca_2d.png`、`tsne_2d.png`、`umap_2d.png` 及对应的 `*_fused_feature_dist.png`：展示不同特征方案在 PCA / t‑SNE / UMAP 空间中的类别分布，辅助分析高 RevPAR 房源在嵌入空间中的聚集形态。  
  - `outputs/*ROC曲线.png`、`*混淆矩阵.png`、`*F1对比图.png`：给出各模型在不同特征方案下的 ROC 曲线、混淆矩阵与 F1 指标对比，用于量化支撑“模型对比与结论”部分的结论。  
  - `outputs/top_listing_analysis.docx` 及 `notebooks/top_listing_text_mining.ipynb` / `top_listing_text_mining.py`：对 Top RevPAR 房源文案的关键词与表达模式进行补充挖掘，为高收益房源画像与业务解释提供定性佐证。  
