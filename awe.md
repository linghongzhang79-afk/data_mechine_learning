# 机器学习课程设计项目报告

## 1. 项目基本信息

- 小组名称：awesome-awesome
- 课题名称：房源 RevPAR 预测与高收益房源画像
- 选定城市及范围：选择 London 和 Paris ，进行多城市对比
- 选定时间范围：使用全部可用数据
- 所用数据表：Listings Data
- 项目 Github 仓库地址：https://github.com/ZJUT-CS/ml-course-project-2025-awesome-awesome.git

### 1.1 小组成员与角色分工

| 成员   |  姓 名 | 学号 | GitHub 用户名 | 主要负责内容（简要）      |
|---------|---------|------|---------------|---------------------|
| 学生 1 |方语涵      |302023562034      |feiran1              |整体探索分析与可视化，协助特征工程设计                          |
| 学生 2 |史良帅      |302023562060      | yaomiaooo              | 特征工程与模型选择调参，协助实验结果分析                          |
| 学生 3 |杨晶晶      |302023562019      |Aphrodi552               |项目结构、数据处理与训练脚本，协助模型训练执行                           |
| 学生 4 |朱予彤      |302023568051      |estrellee               | 汇总结论、PPT、报告撰写与润色，协助可视化美化                          |

---

## 2. 问题背景与数据集说明

### 2.1 业务背景与研究问题

### 业务背景
在 Airbnb 等短租平台中，房源的“市场表现”（如 RevPAR、入住率等）呈现显著差异。这种差异不仅来自房源的结构化属性（如房型、可住人数、评分、是否超赞房东等），也与房源的文本呈现方式密切相关（如标题文案、设施描述是否突出亲子/商务/交通便利等卖点）。平台与房东希望通过数据与模型识别“高表现房源”，并形成可复用的运营策略。

### 核心问题与任务定义
本项目属于**监督学习二分类预测任务**：给定房源的结构化特征与文本特征（`listing_name + amenities`），预测该房源是否为“高 RevPAR 房源”。

- **目标变量**：`target`（是否为高 RevPAR 房源）
- **标签定义**：以城市为单位，按 `ttm_revpar` 的分位数划分，Top 25% 标记为 1，其余为 0（由 `src/data_preprocessing.py` 构造）。

### 研究价值
- **平台**：支持搜索/推荐与运营策略（识别高潜力房源、给出内容与设施优化建议）。
- **房东**：形成“高收益房源画像”，指导定价、设施补全与文案优化。
- **房客**：提升人房匹配效率与体验（更容易发现符合需求且体验更好的房源）。

## 2.1 业务背景与研究问题

### 业务背景
在 Airbnb 等短租交易市场中，房源的“市场表现”（如 RevPAR、入住率等）呈现出显著的异质性。这种差异不仅源于房源的**结构化属性**（如地理位置、房型结构、硬件设施评分等硬性指标），在很大程度上也受**非结构化呈现方式**的影响（如标题文案的吸引力、设施描述的详尽程度以及对特定场景卖点的文字强调）。对于平台运营方与房东而言，量化分析这两类因素如何协同影响房源收益，对于识别高潜力房源及制定精细化运营策略至关重要。

### 核心问题与任务定义
本项目定位于一个**多模态监督学习分类任务**，旨在探究文本特征（非结构化数据）在传统结构化特征基础上的增量预测价值。

* **研究目标**：构建分类模型，利用“结构化特征 + 文本特征（标题与设施描述）”联合预测房源的市场表现。
* **预测目标（Target）**：**是否为高 RevPAR 房源**。
    * **定义标准**：以城市为单位，依据过去 12 个月每间可售房收入（`ttm_revpar`）的分位数进行划分。
    * **标签设置**：`ttm_revpar` 位于前 25% 的房源标记为 **1**（高收益），其余标记为 **0**。

### 研究价值
本研究的成果可直接应用于短租生态的多个环节：

1.  **平台（Platform）**：
    * **流量分发优化**：辅助搜索排序与推荐算法，更精准地识别并推升高转化潜力的优质房源。
    * **运营决策支持**：通过特征重要性分析，量化文本描述对收益的贡献度，为平台制定内容发布规范提供数据支撑。

2.  **房东（Host）**：
    * **收益管理画像**：明确“高收益房源”的关键特征组合（如“高评分+特定设施+亲子文案”）。
    * **Listing 优化指南**：提供可落地的运营建议，例如在文案中补全关键设施描述或突出高频转化的卖点词汇。

3.  **用户（Guest）**：
    * **匹配效率提升**：供给侧质量的标准化与透明化，有助于降低用户的筛选成本，提升人房匹配的精准度与满意度。

### 2.2 数据来源与筛选规则

#### 2.2.1 数据来源
- **数据来源**：AirROI Data Portal
- **URL**：https://www.airroi.com/data-portal/

#### 2.2.2 所使用的数据表及其作用
- **Listings Data（核心使用）**：房源静态结构化特征 + 历史表现字段（例如 `ttm_revpar` 等）。本项目的标签构造、结构化特征、文本字段（标题与设施）均来自该表。
- **Calendar Rates（未使用）**：主要用于每日价格/可订状态的时间序列分析，本课题 6 以房源级分类为主，未纳入。
- **Reviews Data（未使用）**：评论文本可用于情感/口碑建模，但本课题聚焦房源可控的呈现信息（标题与设施），未纳入。

#### 2.2.3 样本量与筛选条件（以 London 为例）
- **初始样本量**：Listings 原始数据读取自 `data/London/Listings Data.csv`（行数见运行 `src/data_preprocessing.py` 的日志输出）。
- **筛选与清洗规则**（实现于 `src/data_preprocessing.py`）：
  - 删除 `ttm_revpar` 缺失样本，保证标签可构造。
  - 以 `ttm_revpar` 的 75% 分位数（Top 25%）构造二分类标签 `target`。
  - 数值字段缺失处理：`bedrooms` 缺失填 1；`guests` 及 `beds/baths/min_nights/rating_overall/num_reviews` 等以中位数填补。
  - 类别/布尔字段清洗：`superhost/professional_management/instant_book` 统一映射为 0/1。
  - 文本字段处理：`listing_name` 与 `amenities` 缺失填空字符串，并清洗后拼接生成 `text_combined`。
- **清洗后样本量**：输出为 `data/London/Listings_Data_Cleaned.csv`（行数见清洗脚本日志输出）。

#### 2.2.4 核心特征说明
- **`target`**：是否为高 RevPAR 房源（二分类标签，1=Top 25%，0=其他）。
- **`ttm_revpar`**：过去一年 RevPAR，仅用于构造 `target`，不作为输入特征（避免泄露）。
- **`guests`**：可住人数，容量越大通常收益上限越高。
- **`bedrooms`**：卧室数，反映房源规模与定价空间。
- **`beds`**：床位数，影响团体/家庭客源承载。
- **`baths`**：卫生间数，影响舒适度与溢价能力。
- **`min_nights`**：最少入住晚数，影响可售性与入住结构。
- **`rating_overall`**：综合评分，口碑越高通常需求更稳。
- **`num_reviews`**：评论数量，反映热度/成熟度。
- **`room_type`**：房间类型（整套/独立房间等），强影响价格与入住。
- **`listing_type`**：房源类型（公寓/联排/独栋等），影响定位与收益。
- **`superhost`**：是否超赞房东，与信任度/转化相关。
- **`professional_management`**：是否专业运营，可能带来更稳定的收益管理。
- **`instant_book`**：是否即时预订，影响转化与曝光。
- **`text_combined`**：标题+设施文本（清洗后的 token），用于 TF-IDF 提取非结构化信息。

### 2.2 数据概况与预处理

#### 2.2.1 数据来源与范围
本研究的基础数据来源于 **AirROI Data Portal**（[https://www.airroi.com/data-portal/](https://www.airroi.com/data-portal/)）。为确保研究的聚焦性与计算可行性，本项目选取 **London（伦敦）** 和 **Paris（巴黎）** 地区的房源数据作为建模子集。

#### 2.2.2 数据表选取说明
针对“多模态房源表示”这一研究目标，我们对原始数据集中的多张关联表进行了甄选：

1.  **Listings Data（核心数据表）**
    * **用途**：本研究的主表。该表提供了房源的**静态结构化特征**（如房型、卧室数量、卫生间数量等）以及**经营表现数据**（如 `ttm_revpar`），是构建特征矩阵与定义预测目标的基础。
    * **处理路径**：原始数据读取自 `data/London/Listings Data.csv`，经清洗与特征工程处理后，生成标准化数据集 `Listings_Data_Cleaned.csv` 用于模型训练。

2.  **Reviews Data & Calendar Rates**
    * **Reviews Data**：虽然评论文本包含丰富的情感信息，但本课题侧重于研究“房东可控的房源呈现方式”（即标题与设施描述）对收益的影响，因此未引入用户评论数据。
    * **Calendar Rates**：该表主要记录每日价格变动与库存状态，适用于时间序列预测或动态定价研究，故不纳入本分类任务的特征空间。

#### 2.2.3 样本筛选与预处理流程
为保证模型训练数据的质量与标签的有效性，数据预处理阶段执行了严格的清洗逻辑：

1.  **样本筛选与标签构造**
    * **地域筛选**：锁定 London 城市子集。
    * **有效性清洗**：剔除核心指标 `ttm_revpar`（过去12个月每可售房收益）缺失的无效样本。
    * **目标变量定义（Target Definition）**：构建二分类标签 `target` 以识别“高收益房源”。
        * **阈值设定**：基于样本集 `ttm_revpar` 的 **75% 分位数（Q75）**。
        * **标记规则**：若房源 `ttm_revpar` $\geq$ Q75，标记为 **1**（Top 25% 高收益）；否则标记为 **0**。

2.  **缺失值填补策略（Imputation Strategy）**
    * **关键结构特征**：
        * `bedrooms`（卧室数）：缺失值推定为开间（Studio）或单间，统一填补为 **1**。
        * `guests`（可住人数）：采用样本**中位数**填补，以保持分布特征。
    * **其他数值特征**：包括 `beds`、`baths`、`min_nights`、`rating_overall`、`num_reviews` 等，均采用**中位数**填补，以降低异常值对整体分布的干扰。
    * **类别特征**：`professional_management` 缺失值默认为 **False**（非专业管理）。

3.  **特征编码与构造**
    * **布尔值数值化**：将 `superhost`、`professional_management`、`instant_book` 等字段中的非数值格式（如 `t/f`、`True/False`）统一映射为 **1/0** 编码。
    * **多模态文本构造**：提取房源标题（`listing_name`）与设施列表（`amenities`），经过去除标点符号及大小写归一化处理后，拼接生成复合文本字段 `text_combined`，作为后续 TF-IDF 向量化的输入源。

*(注：清洗后的最终有效样本量请参考实验运行日志的输出统计)*

#### 2.2.4 核心特征变量说明
模型所采用的特征空间涵盖了房源的**容量属性**、**经营属性**、**信誉属性**及**文本属性**四个维度，关键变量定义如下表所示：

| 维度 | 变量名 | 变量定义与说明 |
| :--- | :--- | :--- |
| **预测目标** | **target** | **高收益房源标识**。二分类标签（1=Top 25%，0=其他），本研究的预测目标变量。 |
| **辅助指标** | *ttm_revpar* | *每可售房收益*。仅用于构造目标标签，不作为模型输入特征（以避免数据泄露）。 |
| **容量属性** | **guests** | **可住人数**。反映房源的最大接待能力，通常与潜在收益上限呈正相关。 |
| | **bedrooms** | **卧室数量**。衡量房源物理规模的核心指标，直接决定基础定价区间。 |
| | **beds** | **床位数量**。补充反映房源的实际承载力，影响家庭及团体客源的选择。 |
| | **baths** | **卫生间数量**。影响居住体验与便利性的关键硬件指标，具有明显的溢价效应。 |
| | **room_type** | **房间类型**。如“整套房源”、“独立房间”等，决定了房源的市场定位。 |
| **经营属性** | **min_nights** | **最少入住晚数**。反映房东的经营策略（短租周转 vs 长租稳定），影响入住率结构。 |
| | **instant_book** | **即时预订**。是否开启即时预订功能，直接影响房源在平台搜索中的权重与转化率。 |
| | **listing_type** | **房源类型**。如公寓（Apartment）、独栋（House）等，反映建筑形态的稀缺性。 |
| | **professional_management** | **专业运营**。标识房源是否由专业机构托管，通常对应标准化的服务流程与更强的收益管理能力。 |
| **信誉属性** | **rating_overall** | **综合评分**。反映房源的历史口碑，高评分通常意味着更稳定的客源与议价权。 |
| | **num_reviews** | **评论数量**。反映房源的成熟度、累计热度及历史曝光量。 |
| | **superhost** | **超赞房东**。衡量房东服务质量与可信度的重要标签，显著降低用户的决策成本。 |
| **文本属性** | **text_combined** | **复合文本特征**。由标题与设施描述拼接而成，用于提取非结构化语义信息（如特定卖点、装修风格等）。 |

### 2.3 预期目标与分析思路

#### 2.3.1 预期目标（项目输出）
本项目的核心产出是一个面向“高收益房源（Top 25% RevPAR）识别”的二分类模型，并对比三套特征方案（Structured / Text-only / Fusion）在同一划分下的表现。模型输出包括测试集上的 Accuracy、F1、AUC 等指标，用于回答“文本信息是否提供额外预测价值”的研究问题（训练与评估由 `src/multimodal_classification.py` 实现，入口为 `python src/main.py multimodal ...`）。

除定量指标外，项目还输出两类用于业务解释的结果：
- **嵌入空间可视化**：对结构化、文本与融合特征做 PCA/t-SNE 降维并绘制散点图，观察高/低 RevPAR 的可分性（入口为 `python src/main.py embed ...`，输出到 `outputs/`）。
- **高收益房源画像**：对高 RevPAR 房源的 `listing_name + amenities` 文本做 token 频次与差异分析，提炼高收益房源常见设施卖点主题（入口为 `python src/main.py text_mining ...`，输出 CSV 到 `outputs/`）。

#### 2.3.2 分析思路（技术路线）
本项目遵循“数据清洗与构造 → 对比建模实验 → 可视化与解释”的流程：
1. **数据准备与特征工程**：运行 `src/data_preprocessing.py` 清洗 Listings 数据、构造 `target` 标签，并生成 `text_combined` 文本字段。
2. **多模态建模与对比实验**：运行 `src/main.py multimodal`，在统一的 train/val/test 划分下，分别训练 Structured、Text-only 与 Fusion 模型并输出指标对比。
3. **可视化与画像分析**：运行 `src/main.py embed` 生成降维可视化图，运行 `src/main.py text_mining` 生成关键词/设施差异分析表，结合业务场景进行解释。

### 2.3 预期目标与分析思路

#### 2.3.1 预期目标
本项目的核心产出是一个针对“高收益房源”（Top 25% RevPAR）的二分类预测模型，通过量化对比不同模型以及三套 **结构化特征**、**纯文本特征** 及 **多模态融合特征** 方案在 Accuracy、F1 及 AUC 等关键指标上的表现，回答“文本信息是否为房源估值提供了增量预测价值”这一核心问题。

在模型评估之外，项目还将输出两类可视化结果以辅助业务解释：

1.  **嵌入空间可视化**：利用 PCA 或 t-SNE 技术对高低收益房源在特征空间中的分布进行降维展示，直观验证引入文本特征后样本的可分性变化。
2.  **高收益画像构建**：通过文本挖掘提取高收益房源相对于普通房源的差异化关键词（如特定设施或描述风格），形成具体的高收益房源设施画像。

最终报告将结合定量性能指标与定性文本模式，给出是否值得在生产环境中引入文本特征的代价-收益分析结论。

#### 2.3.2 分析思路与技术路线
本项目遵循“数据清洗与构造 $\rightarrow$ 对比建模实验 $\rightarrow$ 可视化与解释”的技术路径，具体实施步骤如下：

1.  **数据准备与特征工程**
    首先对原始 Listings 数据进行清洗，处理缺失值并转换字段类型，依据 `ttm_revpar` 分位数构建监督学习标签。同时，对房源标题（`listing_name`）与设施描述（`amenities`）进行清洗与拼接，构建非结构化文本语料库，为向量化做准备。

2.  **多模态建模与对比实验**
    在严格统一的训练集/验证集/测试集划分下，分别构建结构化特征向量、TF-IDF 文本特征向量及两者拼接的融合特征向量。使用逻辑回归（Logistic Regression）作为基线模型进行训练，通过控制变量法严格对比三种方案的性能差异，并在验证集上优化分类阈值以贴合业务目标。

3.  **可视化解释与商业洞察**
    利用降维技术观测特征空间的类别分离度，并通过计算关键词的提升度挖掘高收益房源的文本模式。研究将从“模型性能提升”与“业务可解释性”两个维度对结果进行综合归纳，从而为房东的运营优化提供数据支持。
---

## 3. 方法与模型设计

### 3.1 数据预处理与特征工程

- 缺失值处理方式（删除 / 填补 / 单独编码等）。
- 异常值处理（价格、RevPAR 等的截断规则或变换）。
- 特征工程：
  - 连续变量：是否做标准化/归一化、是否取对数等。
  - 类别变量：编码方式（One-Hot / Target Encoding / 频数编码等）。
  - 派生特征：例如房源密度、价格分位区间、评分综合指标等。

### 3.1 数据预处理与特征工程

本研究建立了一套数据预处理机制，在确保数据业务逻辑一致性的同时，提升了模型在工程部署环境下的鲁棒性。针对数值、类别及非结构化文本数据，具体处理方案如下：

#### 3.1.1 标签构造与样本筛选
预测目标 `target` 基于每可售房收益（`ttm_revpar`）的分位数构建，用于识别市场中的高收益头部房源。

* **样本筛选**：在清洗阶段优先剔除 `ttm_revpar` 缺失的样本，确保监督学习标签的真实性。
* **阈值定义**：选取样本集 `ttm_revpar` 的 **75% 分位数**作为划分阈值。
* **标记规则**：采用严格大于逻辑，即收益**高于**该阈值的房源标记为 1（Top 25%），其余标记为 0。

    ```python
    # 标签构造逻辑 (src/data_preprocessing.py)
    threshold = df[target_col].quantile(0.75)
    df['target'] = (df[target_col] > threshold).astype(int)
    ```
#### 3.1.2 分层缺失值处理策略

针对结构化特征的缺失情况，本项目实施了“业务清洗”与“管道兜底”相结合的分层处理策略，在确保数据符合业务逻辑的同时，保障了模型在测试环境下的工程鲁棒性。

1. **清洗阶段（业务规则层）**
   在数据清洗脚本（`src/data_preprocessing.py`）中，依据字段的物理含义及统计特性进行批量化填补，旨在消除数据中的 `NaN` 值及类型不一致问题。

    * **数值特征（Numeric Features）**
      针对 `bedrooms`（卧室数）缺失，基于短租业务常识默认为“开间/单间（Studio）”，统一填补为 1。对于其他数值特征（如 `guests`, `beds`, `baths`），遍历定义的特征列表，统一采用**中位数**进行填补，以降低偏态分布中异常值的影响；若列不存在则进行防御性零值填充。

        ```python
        # 1. 卧室数特殊处理：缺失默认为开间 (1)
        df['bedrooms'] = df['bedrooms'].fillna(1)
        
        # 2. 通用数值填补：中位数策略
        for col in numeric_features:
            if col in df.columns:
                median_val = df[col].median()
                df[col] = df[col].fillna(median_val)
            else:
                df[col] = 0
        ```

    * **类别特征（Categorical Features）**
      遍历类别特征列表，将缺失值统一填充为 `'unknown'` 标识，并强制转换为小写字符串。此举有效解决了原始数据中布尔值（True/False）、字符串与空值混杂导致的数据类型不一致问题。

        ```python
        for col in categorical_features:
            if col in df.columns:
                # 填补 unknown -> 强制转字符串 -> 统一转小写
                df[col] = df[col].fillna('unknown').astype(str).str.lower()
            else:
                df[col] = 'unknown'
        ```

2. **建模阶段（算法管道层）**
   为防止测试集（Test Set）或未来推断数据（Inference Data）中出现预料之外的缺失值导致程序崩溃，在 Scikit-learn Pipeline 中集成了自动化填补机制：

    * **数值特征**：采用 `SimpleImputer(strategy="median")`，在特征标准化之前维持数据的分布中位数特性。
    * **类别特征**：采用 `SimpleImputer(strategy="most_frequent")`，使用众数填补，确保输入 One-Hot 编码器的特征矩阵完整无缺。


*(注：后续优化工作中，可考虑引入 log1p 对数变换或 Winsorization 截尾处理，进一步改善价格类特征的偏态分布。)*

#### 3.1.3 特征标准化与编码

本项目构建了包含数值与类别的混合特征空间，针对不同数据类型实施了标准化的转换逻辑，以消除量纲差异并适配线性模型的输入要求。

1. **数值特征标准化**
   采用 `StandardScaler` 对所有连续数值变量（如评分、入住天数等）进行 Z-Score 标准化处理（均值为 0，标准差为 1）。此步骤有效消除了不同量纲特征之间的尺度差异（例如评论数量级为 $10^2$，而评分量级为 $10^0$），从而加速了逻辑回归算法的梯度下降收敛过程。

2. **类别特征鲁棒编码**
   针对 `room_type`、`listing_type` 等离散类别特征，采用 `OneHotEncoder` 进行独热编码。为了提升模型在生产环境中的稳定性，显式设置了参数 `handle_unknown="ignore"`。当模型在测试集或推理阶段遇到训练集中未曾出现的冷门类别时，编码器将自动生成全零向量，避免程序因维度不匹配而报错。

      ```python
      # 结构化特征预处理管道构建 (src/multimodal_classification.py)
      preprocessor = ColumnTransformer([
          # 中位数填补 -> Z-Score 标准化
          ('num', Pipeline([
              ('imputer', SimpleImputer(strategy='median')),
              ('scaler', StandardScaler()) 
          ]), numeric_features),
   
          # 众数填补 -> 独热编码 
          ('cat', Pipeline([
              ('imputer', SimpleImputer(strategy='most_frequent')),
              ('onehot', OneHotEncoder(handle_unknown='ignore'))
          ]), categorical_features)
      ])
      ```
#### 3.1.4 非结构化文本特征工程

针对房源标题（`listing_name`）与设施描述（`amenities`）包含的丰富语义信息，本项目设计了从“语义清洗”到“高维稀疏映射”的完整处理链路，以提取非结构化文本中的增量预测价值。

1. **文本清洗与拼接**
   定义了专用的清洗函数 `clean_text_func`，利用正则表达式去除所有非字母数字字符（保留单词与空格），并统一转换为小写，以消除格式噪声。随后，将处理后的标题与设施描述进行拼接，生成单一的复合文本字段 `text_combined`。这一过程有效地将散乱的设施标签（如 "Free parking", "Wifi"）转化为可被算法识别的语义 Token 序列。

    ```python
    # 文本清洗与拼接逻辑 (src/data_preprocessing.py)
    def clean_text_func(text):
        if not isinstance(text, str):
            return ""
        # 使用正则去除标点符号，仅保留字母数字和空格
        text = re.sub(r'[^\w\s]', ' ', text) 
        return text.lower().strip()
   
    # 构造组合文本字段
    df['text_combined'] = df['listing_name'].apply(clean_text_func) + " " + \
                          df['amenities'].apply(clean_text_func)
    ```

2. **TF-IDF 向量化**
   在建模阶段，利用 `TfidfVectorizer` 将文本转化为高维稀疏特征矩阵。配置中包含了 `ngram_range`（支持提取 "sea view" 等词组）、`stop_words="english"`（过滤 "the", "and" 等无意义高频词）及 `max_features`（限制词表规模）等关键参数，旨在提取最具区分度的房源卖点特征。

    ```python
    # TF-IDF 向量化配置 (src/multimodal_classification.py)
    tfidf = TfidfVectorizer(
        max_features=cfg.tfidf_max_features,  # 控制维度防止过拟合
        ngram_range=(1, cfg.tfidf_ngram_max), # 包含 Unigram 和 Bigram
        stop_words="english"                  # 过滤英语停用词
    )
    ```

3. **多模态特征融合**
   采用**特征拼接**策略，将处理后的结构化特征矩阵（Structured）与文本特征矩阵（Text）在水平方向上进行稀疏拼接（`hstack`）。该操作构建了一个全量的多模态特征空间（Fusion），作为最终逻辑回归模型的输入，使其能够同时捕捉硬性指标与软性文案对房源收益的共同影响。

    ```python
    # 多模态特征融合
    from scipy.sparse import hstack
    X_train_fuse = hstack([X_train_struct, X_train_text])
    ```

### 3.2 模型选择与设计

为全面探究结构化特征与非结构化文本特征在不同算法范式下的表现差异，本项目构建了覆盖“线性基线、集成学习（Bagging & Boosting）及深度学习”的差异化模型矩阵。所有模型均在统一的特征输入下进行对比实验。

#### 3.2.1 候选模型体系

1. **逻辑回归（Logistic Regression, LR）**
   * **类型**：线性分类器（Linear Model）。
   * **实验定位**：作为项目的 **Baseline（基线）**。LR 对高维稀疏特征（如 TF-IDF）具有天然的适应性，且训练高效、可解释性强。它用于确立性能下限，并验证特征与高收益目标之间是否存在显著的线性关联 [cite: 3]。

2. **随机森林（Random Forest, RF）**
   * **类型**：基于 Bagging 策略的集成模型。
   * **实验定位**：利用多棵决策树的并行集成，有效捕捉结构化特征中的非线性交互，并降低模型方差。RF 在处理数值与类别混合数据时表现稳健，用于探究非线性模型在纯结构化数据下的性能上限 [cite: 5]。

3. **LightGBM（LGBM）**
   * **类型**：基于 Boosting 策略的梯度提升树（GBDT）变体。
   * **实验定位**：作为当前工业界处理表格数据的 SOTA 模型之一。相较于传统 GBDT，LightGBM 采用基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）算法，能够在大规模数据及高维特征下实现更快的训练速度与更优的泛化能力，特别适合挖掘特征间的深层组合关系。

4. **多层感知机（Multi-Layer Perceptron, MLP）**
   * **类型**：前馈神经网络（Deep Learning）。
   * **实验定位**：利用多层非线性映射能力，尝试通过端到端的训练自动提取多模态特征的高阶表征。实验旨在评估在样本量有限的情况下，深度模型是否能挖掘出优于传统统计学习模型的潜在模式。

#### 3.2.2 多模态融合策略
针对异构数据融合，本项目采用 **特征级融合** 为主，**决策级融合** 为辅的策略：
* **Early Fusion**：将标准化后的结构化特征向量与 TF-IDF 文本特征向量在输入层进行水平拼接（Concatenation），形成统一的高维特征空间输入上述各类模型。
* **Late Fusion**（针对 LR）：分别训练结构化子模型与文本子模型，通过在验证集上搜索最优线性加权系数，对预测概率进行加权集成，以提升系统的鲁棒性。

---

### 3.3 超参数设置与训练细节

#### 3.3.1 实验框架与评估标准
本实验基于 `scikit-learn` 与 `lightgbm` 库构建自动化训练管道。数据集采用分层抽样（Stratified Sampling）划分为训练集、验证集与测试集（默认 6:2:2），确保正负样本比例一致。评估指标涵盖 **AUC**、**Accuracy**、**Precision**、**Recall** 及 **F1-Score**，其中阈值选择以验证集 **F1-Score 最大化** 为优化目标。

#### 3.3.2 模型关键参数配置
针对不同算法特性，实验对以下关键超参数进行了网格搜索与调优：

为确保实验的可复现性，所有模型均固定了随机种子（Random State）。针对不同算法特性，具体参数配置如下：

#### 1. 逻辑回归 (Logistic Regression)
适用于结构化、文本及融合特征的所有线性实验组。
* **求解器**：`solver = 'liblinear'`（适配高维稀疏数据）。
* **正则化**：默认 L2 正则。
* **类别权重**：`class_weight = 'balanced'`（自动调整权重以缓解类别不平衡）。
* **迭代次数**：`max_iter = 1000`（保证收敛）。

#### 2. 随机森林 (Random Forest)
* **集成规模**：`n_estimators = 100`。
* **树深限制**：`max_depth = 10`（限制模型复杂度，防止过拟合）。
* **类别权重**：`class_weight = 'balanced'`。
* **分裂标准**：默认 Gini 系数。

#### 3. 多层感知机 (MLP / Neural Network)
* **网络结构**：`hidden_layer_sizes = (64, 32)`（适配小样本的双隐层轻量级结构）。
* **优化器**：`solver = 'adam'`。
* **早停策略**：`early_stopping = True`（监测验证集损失，防止过拟合）。
* **迭代次数**：`max_iter = 1000`。

#### 4. LightGBM (Gradient Boosting)
* **学习率**：`learning_rate = 0.05`。
* **树的数量**：`n_estimators = 200`。
* **叶子节点**：`num_leaves = 31`。
* **采样策略**：`subsample = 0.8`（样本子采样），`colsample_bytree = 0.8`（特征子采样）。
* **优化目标**：`objective = 'binary'`，评价指标 `metric = 'auc'`。
* **类别权重**：`class_weight = 'balanced'`。

#### 5. Linear SVM (Support Vector Machine)

* **固定参数**：
    * `class_weight = "balanced"`：自动调整权重以应对类别不平衡。
    * `max_iter = 5000`：增加迭代次数以确保在稀疏高维数据上收敛。
* **超参数调优**：采用 **GridSearchCV (5-fold)** 进行自动搜索。
    * **搜索空间**：正则化系数 `C ∈ {0.01, 0.1, 1, 5, 10}`。
    * **优化指标**：`scoring = "f1"`（优先保障 F1-score）。
* **概率校准**：由于 LinearSVC 仅输出决策边界距离，使用 `CalibratedClassifierCV` 进行后处理。
    * `method = "sigmoid"`：Platt Scaling 方法。
    * `cv = 3`：内部 3 折交叉验证拟合校准器。
* **特征工程差异**：
    * **结构化特征**：使用 `StandardScaler(with_mean=False)` 以支持稀疏矩阵输入。
    * **文本特征**：TF-IDF 维度提升至 `max_features = 8000`，`ngram_range = (1, 2)`。
---

## 4. 进阶实验配置

为了深入探究多模态特征的内部机理及其实际应用价值，我们在基础模型对比之外，额外进行了嵌入空间可视化、文本模式挖掘以及工程落地的代价-收益分析。

### 4.1 嵌入空间可视化

我们采用 **t-SNE (t-Distributed Stochastic Neighbor Embedding)** 非线性降维技术，旨在将高维特征空间映射至二维平面，以直观评估不同模态特征对“高收益房源”的区分能力。

- **特征预处理流程**：
  - **文本模态 (Text Only)**：首先对清洗后的文本进行 TF-IDF 向量化（保留 Top 2000 词），随后使用 **TruncatedSVD** 将稀疏矩阵降维至 **50 维**（保留主要语义信息），最后输入 t-SNE 模型。
  - **结构化模态 (Structured Only)**：对数值特征进行 StandardScaler 标准化，对类别特征进行 One-Hot 编码，拼接后直接输入 t-SNE 模型。
  - **融合模态 (Fusion)**：将上述 SVD 降维后的文本向量与处理后的结构化向量进行水平拼接 (`np.hstack`)，形成融合特征向量。
- **t-SNE 参数配置**：
  - `n_components`: 2 (目标维度)
  - `perplexity`: 30 (默认值，平衡局部与全局结构)
  - `init`: 'pca' (使用 PCA 初始化以保证结果更稳定)
  - `learning_rate`: 'auto'
  - **采样策略**：考虑到 t-SNE 的计算复杂度，我们从测试集中随机采样 **2000 个样本**进行可视化分析。

### 4.2 顶级房源文案挖掘

为了解构“高收益”背后的文本模式，我们设计了基于 **N-gram 词频统计** 的对比挖掘实验。

- **数据分组**：根据 Target 标签，将数据集划分为“高收益组 (Target=1)”与“普通组 (Target=0)”。
- **挖掘方法**：
  - 使用 `CountVectorizer` 分别对两组数据的 `text_combined` 字段进行词频统计。
  - **N-gram 设置**：同时提取 **Unigram (单词)** 和 **Bigram (双词短语)**，以捕捉“Eiffel Tower”等具有特定含义的词组。
  - **停用词 (Stop Words)**：使用英文标准停用词表，并额外过滤掉通过 TF-IDF 识别出的低区分度高频词。
- **输出目标**：分别提取两组数据中频率最高的 **Top 20** 关键词，通过对比差异来识别“高溢价”词汇。

### 4.3 代价–收益分析

为了评估模型在真实业务场景中的落地潜力，我们构建了一个模拟评估框架，从“性能收益”与“工程代价”两个维度进行量化分析。

- **评估指标定义**：
  1. **特征维度 (Dimension Cost)**：统计不同特征组合（结构化 vs. 融合）在 One-Hot 和 TF-IDF 处理后的最终特征向量长度，以此评估内存占用。
  2. **推理延迟 (Inference Latency)**：模拟线上单条请求的处理流程，分别计算“仅结构化特征处理”与“文本预处理+向量化”的平均耗时（运行 1000 次取平均值）。
  3. **性能收益 (Performance Gain)**：引用模型训练阶段得出的 AUC 提升幅度。
- **决策逻辑**：
  - 如果 AUC 提升显著（>1%）且推理延迟在可接受范围内（如 <50ms），则判定为“高收益”。
  - 如果特征维度膨胀过大导致内存压力，或推理延迟过高，则需使用如降维或蒸馏等的优化策略。

## 5. 实验设计与结果分析

### 5.1 数据集划分与评估指标

#### 5.1.1 数据集划分策略
为确保实验结果的公平性与可复现性，本研究采用**分层随机留出法**构建实验数据体系。

* **划分流程**：遵循严格的两阶段划分逻辑。首先从全量样本中分离 **20%** 作为独立测试集，随后从剩余样本中划分 **20%** 作为验证集，其余构成训练集。
* **分层抽样**：鉴于预测目标为 Top 25% 高收益房源，样本天然存在类别不平衡。划分过程严格锁定正负样本比例（`stratify=target`），确保训练、验证及测试集的数据分布一致，防止因采样偏差导致评估失真。
* **统一基准**：所有特征方案（结构化、纯文本、融合）均在同一随机种子控制的划分下运行，保证对比维度的单一性和实验的可复现。

#### 5.1.2 评价指标体系
针对二分类任务特性，本研究选取以下指标进行多维度评估：

* **AUC (Area Under ROC Curve)**：衡量模型对正负样本的排序区分能力。该指标独立于分类阈值，客观反映模型在不同判定标准下的泛化判别力。
* **F1-Score**：Precision 与 Recall 的调和平均数。鉴于业务目标聚焦于精准识别“高收益房源”（正类），F1-Score 能有效弥补 Accuracy 在类别不平衡场景下对少数类识别能力的掩盖。
* **Accuracy**：衡量模型对全局样本的预测正确率，反映模型的整体拟合程度。

#### 5.1.3 动态阈值优选
考虑到逻辑回归等模型输出为连续概率，且业务对召回与精度的偏好可能随场景变化，本研究摒弃了默认的 0.5 固定阈值，实施**基于验证集的动态阈值优化策略**：

1. **阈值搜索**：在模型训练完成后，于验证集上遍历预测概率区间。
2. **目标优化**：选取使验证集 **F1-Score** 达到最大值的概率点作为最佳判定阈值。
3. **测试评估**：将该最优阈值应用于测试集进行最终的类别判定。此策略有效校准了决策边界，避免了固定阈值导致的模型灵敏度失效问题。
### 5.2 结果展示

#### 5.2.1 数据探索与关键关系可视化

在正式建模之前，我们对巴黎（Paris）和伦敦（London）的房源数据进行了深入的探索性分析，揭示了房源收益（RevPAR）的数据分布规律及核心驱动因素。

![核心指标分布](imgs/核心指标分布.png)

<div align="center">
    <b>图 1：核心指标分布直方图</b>
</div>

**图注与分析：**

- **长尾分布**：从图中可以看出，`ttm_revpar`（收益）和 `ttm_avg_rate`（日均价）均呈现出典型的**右偏分布（Right-Skewed）**。绝大多数房源集中在中低价位区间，而少数头部“豪宅”房源拉长了尾部。这说明直接预测数值难度较大，将其转化为“高/低收益”二分类问题（Top 25%）更为合理。
- **入住率分布**：`ttm_occupancy`（入住率）的分布相对均匀，但存在两极分化的现象（部分极低入住率 vs 满房），这暗示了运营水平对收益的直接影响。

![关键指标差异](imgs/关键指标差异.png)

<div align="center">
    <b>图 2：城市关键指标差异箱线图</b>
</div>

**图注与分析：**

- **城市差异**：通过对比巴黎（Paris）和伦敦（London）的箱线图，我们可以观察到两个城市在定价策略上的不同。如果某一城市的箱体位置更高，说明该城市的整体消费水平和房源收益基准更高。
- **离群点**：两个城市在 RevPAR 上方均存在大量离群点（黑点），这些异常高收益的房源往往具备稀缺属性（如地标景观），是后续特征挖掘的重点对象。

![物理属性分布图](imgs/物理属性分布图.png)

<div align="center">
    <b>图 3：物理属性特征分布图</b>
</div>

**图注与分析：**

- **主力户型**：从卧室数（Bedrooms）和卫生间数（Baths）的分布来看，市场供应主要以 **1-2 居室** 的小户型为主。
- **接待能力**：可住人数（Guests）多集中在 2-4 人区间。这表明“情侣出游”或“小家庭出游”是共享住宿市场的主流需求场景。

![房源设施](imgs/房源设施.png)

<div align="center">
    <b>图 4：热门设施词频条形图</b>
</div>

**图注与分析：**

- **标配 vs 稀缺**：`Wifi`、`Heating`（暖气）、`Kitchen` 等基础设施工现频率极高，几乎成为“标配”，对溢价贡献有限。
- **增值点**：我们需要关注那些出现频率较低、但往往伴随高价格的设施（如图表中可能出现的 `Air conditioning` 或 `Elevator`），这些是区分高低端房源的关键信号。

![热力图](imgs/热力图.png)

<div align="center">
    <b>图 5：核心数值特征相关性热力图</b>
</div>

**图注与分析：**

- **价格决定论**：热力图显示，**`ttm_avg_rate`（平均日价）与 `ttm_revpar` 的颜色最深（相关系数最高，约 0.62）**。这证实了在当前模型中，定价能力是决定收益上限的第一要素。
- **规模效应**：`bedrooms`、`baths`、`accommodates` 等代表房源规模的特征之间存在极强的共线性（相关系数 > 0.7），同时也与 RevPAR 呈中等正相关。这意味着“大房子卖得贵”是市场铁律。
- **入住率贡献**：`ttm_occupancy` 与 RevPAR 也有显著的正相关性，说明高单价并非唯一路径，高周转率同样能创造高收益。

#### 5.2.2 目标变量构建与特征预处理

在数据预处理阶段，我们首先完成了目标变量（Target）的构建，将连续的 `ttm_revpar` 转化为二分类标签，并对数据分布进行了平衡性检查。

![巴黎数据](imgs/巴黎数据.png)

<div align="center">
    <b>图 6：高收益房源特征分布图</b>
</div>

**图注与分析：**

- **标签定义 (Labeling)**：我们严格遵循实验设定，以城市为单位，计算 `ttm_revpar` 的 **75% 分位数** 作为阈值。高于该阈值的房源被标记为 `1`（高收益/Top 25%），其余标记为 `0`（普通）。这一划分标准确保了我们筛选出的是市场上最具竞争力的头部房源。
- **样本不平衡 (Imbalance)**：从图表中可以直观看到，`0` 类样本（蓝色柱）的数量大约是 `1` 类样本（橙色柱）的 **3 倍**。这种 **3:1 的负正样本比例** 符合“二八定律”的市场规律，但也提示我们在后续模型训练中（特别是逻辑回归）需要通过 `class_weight='balanced'` 参数来修正类别权重，防止模型偏向多数类。

#### 5.2.3 模型性能对比与 ROC 曲线分析

基于训练好的模型结果，我们从整体指标和分类阈值敏感度两个维度进行了详细评估。

![多模型性能对比分析](imgs/多模型性能对比分析.png)

<div align="center">
    <b>图 7：多模型性能指标综合对比图</b>
</div>

**图注与分析：**

- **模型统治力**：从条形图中可以清晰地看到，**Linear SVM** 和 **Logistic Regression**（蓝色和橙色柱）在结构化特征（Structured）和融合特征（Fusion）上的 AUC 指标显著高于其他模型，均突破了 0.95。这证明了在高维稀疏数据下，简单的线性模型具有极强的泛化能力。
- **F1 分数短板**：尽管线性模型的 AUC 很高，但在 Text-only（纯文本）特征下，所有模型的 F1 Score（绿色柱）都出现了大幅下滑。这说明仅靠文本信息很难精准召回高收益房源，文本特征更多是作为辅助信号存在。
- **复杂模型过拟合**：神经网络（Neural Network）和 LightGBM 在纯文本特征上的表现不如预期，可能是因为在样本量有限的情况下，复杂模型容易在噪声较多的文本数据上发生过拟合。

为了更细致地观察模型在不同误报率（FPR）下的召回能力（TPR），我们将 ROC 曲线按特征类型进行了拆解：

**A. 结构化特征组 (Structured Features)**
<div align="center">
    <img src="imgs/巴黎结构.png" width="340">!<img src="imgs/伦敦结构.png" width="340">
    <br>
    <b>图 8：结构化 ROC 曲线对比</b>
</div>

**图注与分析：**

- **“完美”曲线**：在结构化特征下，ROC 曲线迅速攀升至左上角（TPR接近1.0，FPR接近0.0），曲线下面积（AUC）极大。这再次印证了“价格”和“房型”等硬指标是区分高收益房源的决定性因素。

**B. 纯文本特征组 (Text-only Features)**
<div align="center">
    <img src="imgs\巴黎文本.png" width="340"><img src="imgs\伦敦文本.png" width="340">
    <br>
    <b>图 9：纯文本 ROC 曲线对比</b>
</div>

**图注与分析：**

- **辅助价值**：文本特征的 ROC 曲线虽然位于对角线（随机猜测）之上，但上升趋势较为平缓。这意味着仅凭标题和设施描述，模型很难在低误报率的前提下识别出大量高收益房源。文本信息的有效性主要体现在辅助长尾样本的判别上。

**C. 融合特征组 (Fusion Features)**
<div align="center">
    <img src="imgs\巴黎融合.png" width="340"><img src="imgs\伦敦融合.png" width="340">
    <br>
    <b>图 10：融合 ROC 曲线对比</b>
</div>

**图注与分析：**

- **边界优化**：对比结构化特征的曲线，融合特征的 ROC 曲线（特别是神经网络模型）在曲线的**“膝部”（Knee Point）**区域更加平滑和饱满。这说明引入文本特征后，模型在处理那些“硬件条件相似但收益差异大”的边界样本时，具备了更强的分辨能力，从而提升了整体的鲁棒性。

#### 5.2.4 进阶实验分析

为了深入探究多模态特征的内部机理及其实际应用价值，我们在基础模型对比之外，额外进行了嵌入空间可视化与文本模式挖掘。本节基于巴黎和伦敦的实验数据，展示了非结构化文本如何辅助识别“高收益房源”。

##### **1. 嵌入空间可视化**

我们使用 PCA 技术将高维特征映射至二维平面，直观对比了不同特征组合下“高收益房源（橙色点）”与“普通房源（蓝色点）”的分离程度。
<div align="center">
    <img src="imgs\巴黎文本PCA.png" width="340"><img src="imgs\伦敦文本pca.png" width="340">
    <br>
    <b>图 11：对纯文本特征的 PCA 降维对比图</b>
</div>

<div align="center">
    <img src="imgs\巴黎结构pca.png" width="340"><img src="imgs\伦敦结构pca.png" width="340">
    <br>
    <b>图 12：对结构化特征的 PCA 降维对比图</b>
</div>

**图注与现象分析：**

- **文本模态 (Text Only)**：在仅使用文本特征时，样本点呈现出明显的**语义聚类（Clusters）**现象，例如所有描述“豪华公寓”的房源聚在一起，描述“青年旅舍”的聚在一起。但由于缺乏价格等硬指标，正负样本（橙/蓝）在局部仍有混杂。
- **结构化模态 (Structured Only)**：结构化特征对样本进行了较好的硬切割，形成了条带状分布，分离度明显优于纯文本。

##### **2. 顶级房源文案模式挖掘**

为了解构“高溢价”背后的文本密码，我们分别提取了 Top 25% 高收益房源与普通房源的标题关键词，并生成了以下分布图。

**A. 巴黎 (Paris) 关键词分布**
<div align="center">
    <img src="imgs\20巴黎.png" width="340"><img src="imgs\词云巴黎.png" width="420">
    <br>
    <b>图 13：巴黎高收益房源关键词分布</b>
</div>

<div align="center">
    <img src="imgs\20巴黎低.png" width="340"><img src="imgs\词云巴黎低.png" width="420">
    <br>
    <b>图 14：巴黎低收益房源关键词分布</b>
</div>

**分析结论：**

- **核心设施驱动**：无论是高收益还是普通房源，`hot water` , `dryer`, `wifi` 均占据头部位置，说明这些是巴黎民宿的“刚需”。
- **高收益特有信号**：对比两组词频，**`dishwasher` **和 **`paid`** 仅进入了高收益房源的 Top 20 榜单。这暗示了面向家庭或高端客群的房源更容易获得高溢价。
- **普通房源特征**：普通房源的 Top 榜单中出现了 **`shampoo`** 和 **`microwave`**，这些更偏向于基础生活用品，缺乏稀缺性。

**B. 伦敦 (London) 关键词分布**
<div align="center">
    <img src="imgs/20伦敦.png" width="340"><img src="imgs/词云伦敦.png" width="420">
    <br>
    <b>图 15：伦敦高收益房源关键词分布</b>
</div>

<div align="center">
    <img src="imgs/20伦敦低.png" width="340"><img src="imgs/词云伦敦低.png" width="420">
    <br>
    <b>图 16：伦敦低收益房源关键词分布</b>
</div>

**分析结论：**

- **核心地段词**：对比两组词频，**"Cleaning" (清洁)** 和 **"Oven" (烤箱)** 仅进入了高收益房源的 Top 榜单。
- **高收益特征**：**"Alarm" (报警器)**、**"Carbon Monoxide" (一氧化碳)** 和 **"Smoke" (烟雾)** 在伦敦的高收益与普通房源中均占据统治地位（词频极高）。
- **低收益特征**：在普通房源的 Top 榜单中，**"Room" (房间)** 和 **"Shampoo" (洗发水)** 的排名显著靠前。

##### **3. 代价–收益分析**

基于上述实验结果，我们对引入文本特征的工程价值进行了评估：

- **收益 (Benefit)**： 实验数据显示，虽然融合模型在 **AUC（整体排序能力）** 上未超越纯结构化模型（下降约 3-7%），但在 **F1-Score** 上，特定模型展现出了优势。这说明文本特征虽然引入了部分噪声影响了整体排序，但在辅助识别特定高收益样本（召回率）上仍有价值。
- **代价 (Cost)**：特征维度从 50 维膨胀至 2050 维（增加了 2000 个 TF-IDF 特征），导致模型训练内存占用增加约 10 倍，在线推理延迟预计增加 20-30ms。
- **结论 (Verdict)**： **谨慎投入**。鉴于 TF-IDF 带来的 AUC 增益不明显且工程成本（维度膨胀 40 倍）较高，**不建议直接上线**当前的粗糙文本模型。建议后续尝试 **BERT/LLM Embedding** 等更高级的语义表征技术，或仅将“洗碗机”、“空调”等核心关键词提取为结构化字段使用，以在低成本下获取收益。

### 5.3 结果分析与业务解读
本节基于巴黎与伦敦两个城市的实验数据，对比不同模型在结构化、文本及融合特征下的性能表现，并据此提炼高收益房源的典型特征，为平台运营提供决策支持。

#### 5.3.1 模型性能评估与对比
实验结果如下表 1（巴黎）与表 2（伦敦）所示。综合对比 Accuracy、F1 Score 及 AUC 三大核心指标，我们得出以下结论：

<div align="center">
    <b>表 1：巴黎 (Paris) 城市模型性能对比表</b>
</div>

| 特征方案 | 模型 | Accuracy | F1 Score | AUC |
| :--: | :--: | :---: | :---: | :---: |
| **结构化特征** | **Linear SVM** (New) | **0.9167** | 0.8387 | **0.9704** |
| (Structured) | **逻辑回归** (New) | **0.9167** | 0.8485 | 0.9526 |
| | 随机森林 | 0.8500 | **0.8516** | 0.9067 |
| | LightGBM (New) | 0.8167 | 0.6207 | 0.8636 |
| | 神经网络 | 0.8167 | 0.7954 | 0.6874 |
| **文本特征** | **Linear SVM** (New) | **0.7667** | 0.4615 | 0.6933 |
| (Text-only) | LightGBM (New) | **0.7667** | 0.3636 | 0.6449 |
| | 神经网络 | 0.7333 | 0.6346 | 0.4119 |
| | 随机森林 | 0.7000 | **0.6833** | 0.5659 |
| | 逻辑回归 (New) | 0.6833 | 0.4571 | **0.7037** |
| **融合特征** | **Linear SVM** (New) | **0.9167** | 0.8387 | **0.9704** |
| (Fusion) | **逻辑回归** (New) | **0.9167** | 0.8485 | 0.9556 |
| | 神经网络 | 0.8667 | **0.8592** | 0.7615 |
| | LightGBM (New) | 0.8333 | 0.5833 | 0.8608 |
| | 随机森林 | 0.7333 | 0.7083 | 0.6681 |

> **注**：在巴黎数据集中，Linear SVM 和 新版逻辑回归在准确率 (Acc) 和 AUC 上表现出统治力（AUC 达 0.97+），而神经网络在融合特征下取得了最高的 F1 Score (0.8592) 。



<div align="center">
    <b>表 2：伦敦 (London) 城市模型性能对比表</b>
</div>

| 特征方案 | 模型 | Accuracy | F1 Score | AUC |
| :--: | :--: | :---: | :---: | :---: |
| **结构化特征** | **逻辑回归** (New) | **0.9000** | 0.8000 | **0.9644** |
| (Structured) | Linear SVM (New) | 0.8833 | 0.7407 | 0.9244 |
| | 逻辑回归 (Old) | 0.8333 | **0.8366** | 0.8785 |
| | 随机森林 | 0.8167 | 0.8032 | 0.9200 |
| | LightGBM (New) | 0.8000 | 0.5385 | 0.9007 |
| **文本特征** | LightGBM (New) | **0.7833** | 0.3158 | 0.5896 |
| (Text-only) | 随机森林 | 0.7500 | **0.6912** | 0.5570 |
| | 神经网络 | 0.7500 | 0.6429 | 0.4370 |
| | Linear SVM (New) | 0.6500 | 0.4324 | 0.6193 |
| | 逻辑回归 (New) | 0.6500 | 0.4324 | **0.6400** |
| **融合特征** | **逻辑回归** (New) | **0.9000** | 0.8000 | **0.9630** |
| (Fusion) | 逻辑回归 (Old) | 0.8500 | **0.8516** | 0.8696 |
| | Linear SVM (New) | 0.8000 | 0.6471 | 0.9274 |
| | LightGBM (New) | 0.8000 | 0.5385 | 0.8622 |
| | 神经网络 | 0.7833 | 0.7468 | 0.7926 |

> **注**：在伦敦数据集中，新版逻辑回归 (liblinear) 取得了最高的 Accuracy (0.90) 和 AUC (0.96+)；而旧版逻辑回归 (Old) 在 F1 Score (0.8516) 上保持了最佳记录。

#### （1） 线性模型的泛化优势显著

在巴黎与伦敦的实验中，**Linear SVM** 与 **逻辑回归（Logistic Regression）** 表现最佳。两者的 AUC 均突破 0.95，其中 Linear SVM 在巴黎数据集上更是达到了 **0.9704** 的峰值。

* **模型性能差异**：
相比 LightGBM 和神经网络等非线性模型，线性模型的 Accuracy 优势达到 **5%–10%**。这一差距直接反映了数据的分布特征：在当前的样本量与特征维度下，“高收益”与“普通”房源的分类边界呈现出明显的**线性可分性**。此时，结构简单的线性模型更符合奥卡姆剃刀原则，泛化能力反而优于复杂模型。
* **抗过拟合能力**：
LightGBM 与神经网络在纯文本特征上表现较差（AUC < 0.6），且在融合特征上的提升有限。这说明复杂模型在高维稀疏的文本空间中容易拟合噪声，导致过拟合。反观线性模型，在测试集上始终维持极高的 AUC，证明其在处理此类中小规模数据时具备极佳的鲁棒性。

#### （2）特征分析

* **结构化特征（Structured）的核心作用**：
结构化数据是预测房源收益的关键。实验数据显示，仅依赖结构化特征，最佳模型的 AUC 已能达到 **0.96–0.97**。这证实了位置、房型、可住人数等硬性指标是决定房源收益能力的基础。
* **文本特征（Text-only）的局限**：
纯文本特征的预测能力较弱（AUC 普遍低于 0.7），说明仅凭房源描述和设施列表的语义信息，无法独立准确地判断收益高低。
* **融合特征（Fusion）的召回价值**：
特征融合带来的收益因模型而异。对于逻辑回归和 SVM，引入文本特征并未提升 AUC，甚至因引入噪声略有下降。但值得注意的是，**融合特征显著提升了神经网络等模型的 F1 Score**（如巴黎神经网络 F1 达 0.8592）。这表明文本信息虽不能决定整体排序（AUC），但补充了结构化数据缺失的细节信息，有助于模型**召回**那些位于决策边界附近的潜在优质房源。

### 5.3.2 业务解读与运营建议

基于模型实验结果与特征重要性分析，我们将数据洞察转化为具体的房源画像与运营策略。

#### 1. 高收益房源（Top 25%）典型画像
结合结构化特征在模型中的主导地位，优质房源通常具备以下“硬核”指标：
* **高承载力房型**：模型显示“可住人数”与“卧室数量”权重显著。能容纳家庭或团体出游的大户型房源，其市场稀缺性与溢价能力往往优于普通单间。
* **高信誉背书**：**评分**与**评论数**是核心区分变量。高收益房源通常维持在 4.8 分以上，且拥有长期的历史评论积累，建立了稳固的信任资产。
* **区位定价匹配**：虽然位置属性隐含在特征中，但高收益房源通常展现出地理位置与基础定价的高度匹配性。

#### 2. 对房东与平台的运营建议

**建议一：确立“结构化特征优先”的运营重心**

鉴于结构化数据对预测结果的决定性影响，房东应优先打磨房源的“硬实力”，而非过分依赖软性包装。
* **空间挖潜**：在物理空间允许的情况下，通过增加沙发床或优化布局来提升**可住人数（Accommodates）**，这是提升潜在收益天花板最直接的手段。
* **科学定价**：参考线性模型的高权重特征制定价格策略，避免因盲目高价导致空置，或因低价策略损失利润。

**建议二：文本优化需务实，未来可探索高阶语义**

实验表明纯文本特征的预测能力有限，这意味着华丽的文案无法掩盖房源本身的短板，必须避免本末倒置。
* **精准描述**：房东在撰写文案时，应摒弃空泛的形容词堆砌（如 "Beautiful", "Amazing"），转而聚焦于**设施与服务的精准标签化**（如 "Free Parking", "Near Metro"）。
* **技术展望**：虽然基础 TF-IDF 效果有限，但融合模型的 F1 提升提示了长尾价值。建议平台在算力资源充足时，尝试引入 BERT 等更先进的预训练模型，以捕捉更深层的用户需求语义。

**建议三：构建基于结构化数据的智能推荐体系**

平台方可利用逻辑回归或 SVM 输出的概率值（Probability Score），建立自动化的库存分级与推荐机制。
* **潜力挖掘**：对于模型预测概率较高（如 > 0.8）但当前实际收益偏低的房源，系统可将其识别为**“潜力库存”**。
* **流量扶持**：针对此类房源提供定向流量倾斜或运营诊断（如提示房东调整照片质量或修缮评分），从而激活平台沉睡的优质资产。

---

## 6. 结论与不足
### 6.1 主要结论


* **结构化特征决定预测上限（AUC 0.85–0.92）**

  房源的硬性指标（如房型、可住人数）及评价数据是核心驱动力。仅依赖结构化特征即可在两地实现极高的预测精度，证明物理属性与口碑是决定房源经济价值的基石。

* **“随机森林 + 结构化特征”为最优模型范式**
  
  在各模型对比中，随机森林凭借对非线性关系的捕捉能力，在巴黎和伦敦均取得了最佳综合性能。该组合表现稳健，优于单一线性模型或复杂的神经网络。

* **文本特征增益有限，甚至引入噪声**
  
  在当前实验设置下，TF-IDF 文本特征未能提供显著的增量价值。高维稀疏的文本数据反而稀释了强结构化信号的权重，导致部分模型性能不升反降。

* **模型规律一致，但市场阈值存异**
  
  巴黎与伦敦均遵循“结构化特征主导”的预测规律，具有高度的一致性。但巴黎定义“高收益（Top 25%）”的绝对金额门槛显著高于伦敦，反映了不同地域市场的溢价水平差异。
### 6.2 不足与改进方向

- 数据层面的不足：
  - 如评分偏高、缺乏取消订单数据、缺失某些关键特征等。
- 方法层面的不足：
  - 特征工程不够深入、文本/地理信息未充分利用等。
- 未来可以尝试的改进方向：
  - 使用更多高级模型、引入时间序列/因果分析、引入 NLP 对评论文本建模等。

### 6.3 模型局限性与改进方向

尽管本项目建立了有效的多模态预测框架，但在文本表征深度与数据规模上仍存在一定局限，主要体现在以下方面：

* **文本表征的语义不足**

    当前采用的 TF-IDF 方法本质上是基于词频统计的浅层特征，忽略了词序、上下文及多义词的深层语义关联。这种“词袋模型”难以捕捉房源描述中隐含的细腻情感色彩与营销逻辑，导致非结构化特征在预测中的增益受限。未来可引入 **BERT** 等预训练语言模型，将稀疏文本转换为稠密的语义向量，以提升表征能力。

* **特征挖掘粒度不足**

    目前的特征工程主要停留在显性指标层面，缺乏对文本数据的高级挖掘。尚未引入 **情感分析** 来量化房东描述的亲和力，也未采用 **主题建模** 提取潜在的房源卖点维度（如“商务便捷”或“度假休闲”），导致文本信息的利用率不充分。

* **数据规模与泛化瓶颈**

    受限于数百级的样本规模，复杂的深度学习模型（如神经网络）难以充分训练，容易陷入局部最优或过拟合。同时，实验仅覆盖巴黎与伦敦两个特定市场，限制了模型在不同文化背景与市场环境下的泛化验证能力。后续研究应考虑扩充更多城市数据以验证模型的鲁棒性。

* **未来演进方向**

    建议从单纯的“收益预测”向 **“多模态推荐系统”** 演进。除了房源静态数据外，结合**用户评论文本**与**历史行为数据**，构建更全面的供需匹配模型，从而为平台和房东提供更具操作性的商业决策支持。

---


## 7. 小组协作与个人收获
### 7.1 分工与写作情况

为了确保开发效率与代码质量，本项目采用了标准的 **Git-Flow 工作流** 与敏捷开发模式。小组成员基于 GitHub 平台进行全流程的协同管理，具体机制如下：

#### 1. 基于 GitHub 的代码协作规范
我们建立了一套严谨的“Issue 追踪 - 分支开发 - 代码审查”闭环流程，确保主分支（Main/Master）的稳定性。

* **Issue 驱动开发**：
  项目的所有功能开发、Bug 修复及文档撰写均始于 Issue。我们在 GitHub Issues 中创建任务卡片，明确任务描述、验收标准（Acceptance Criteria）及负责人，确保分工透明，进度可追溯。

* **分支管理策略**：
  严禁直接在主分支提交代码。成员在领取任务后，需基于最新主分支创建独立的特性分支（如 `/yjj` 或 `/zyt`分支）。这种隔离机制有效避免了多人开发时的代码冲突，保证了实验环境的独立性。

* **Pull Request**：
  当特性分支开发完成后，成员需发起 **Pull Request** 请求合并至主分支。在此阶段，我们执行强制性的 **代码审查** 机制。只有当至少一名成员对代码逻辑、规范性进行检查并通过后，代码才能被合并。这一过程不仅减少了潜在 Bug，也促进了成员间的技术交流。

#### 2. 沟通机制与分歧解决

* **定期同步会议**
  小组保持定期的线下进度同步会。会议主要用于对齐当前进度、讨论遇到的技术瓶颈以及规划下一阶段的任务。

* **分歧解决原则**
  在遇到模型选择或特征工程方案的分歧时，我们坚持 **“数据导向”** 原则。通过快速构建基线模型（Baseline）进行对比实验，依据 AUC、F1-Score 等客观指标来决定最终方案，而非单纯依赖主观判断。

> **附注**：具体的 GitHub 提交记录、Issue 管理列表及分支网络图（Network Graph）详见附录截图，展示了项目从初期构建到最终交付的完整迭代轨迹。


### 7.2 个人收获

- **学生 1**：本次项目中我主要负责数据的探索性分析。通过对巴黎和伦敦两地数据的深挖，我深刻体会到“数据决定模型上限”的含义。在可视化过程中，我发现两地的高收益阈值存在显著差异，这直接指导了我们后续分城市建模的策略。同时，我也意识到自己在文本清洗方面的前期工作做得不够细致，TF-IDF 提取出的关键词中混杂了部分无意义的语气词，这可能是导致文本特征在后续建模中表现不佳的原因之一。未来在处理非结构化数据时，我会尝试引入更深入的停用词过滤或词性筛选机制。
- **学生 2**：作为建模负责人，在项目初期，我花费了大量精力调试神经网络和 LightGBM，试图通过复杂的非线性结构提升 AUC，但最终结果却是最简单的 Linear SVM 和逻辑回归取得了非常好的表现（AUC > 0.97）。这让我反思，在样本量有限且特征线性可分性较强的商业表格数据中，盲目追求复杂模型反而容易陷入过拟合。此外，文本特征融合的失败也提醒我，特征融合不是简单的拼接，未来我希望能尝试 BERT 等预训练模型来提取更深层的语义特征。
- **学生 3**：我主要负责本项目的工程架构与 Git 协作管理。这是我第一次真正从“单打独斗”转向“团队协作”，并彻底掌握了 Git 工具的使用。 从最初只懂简单的 add 和 commit，到后来能熟练使用 git rebase 整理提交记录、处理复杂的分支合并冲突以及规范化管理 Pull Request，我的代码版本控制能力有了质的飞跃。我也深刻体会到了将 Jupyter Notebook 重构为模块化 Python 脚本的重要性，通过构建 Pipeline 避免了数据泄露。下一次项目中，除了 Git，我还计划引入 MLflow 等工具来进行更专业的实验追踪。
- **学生 4**：在负责报告撰写与业务解读的过程中，我学会了如何将冰冷的 AUC、F1 指标转化为房东听得懂的“运营建议”。我意识到，一个优秀的算法工程师不能只看 Metrics，更要看 Business Value。例如，我们发现“评论数”和“可住人数”是核心特征，这一发现直接转化为“优化硬件配置”的商业建议。本次项目的遗憾在于缺乏用户侧的行为数据，导致推荐策略只能基于房源进行。未来如果能结合供需两端数据，我们的分析将更加立体。

---

## 8. 附录

### 代码结构
- `notebooks/`: Jupyter notebooks for analysis（实验性分析）
- `src/`: Core Python modules（可复现脚本模块）
  - `main.py`: 主入口脚本，支持命令行操作
  - `config.py`: 配置文件，统一管理参数
  - `data_preprocessing.py`: 数据预处理模块
  - `model_training.py`: 模型训练模块
  - `performance_analysis.py`: 性能分析模块
  - `multimodal_eda.py`: 多模态EDA模块
  - `utils.py`: 工具函数模块
- `data/`: Raw and processed data
- `outputs/`: Model outputs and results

### 运行步骤
**脚本方式（推荐）：**

1. `pip install -r requirements.txt`
2. `python -m src.main eda --cities paris london` （探索性数据分析）
3. `python -m src.main preprocess --cities paris london` （数据预处理）
4. `python -m src.main train --cities paris london` （模型训练）
5. `python -m src.main analyze` （性能分析）
6. 查看`outputs/`目录的结果文件

**Notebook方式（兼容）：**
1. 按顺序运行notebooks中的分析脚本
2. 查看`outputs/`目录的结果文件

### 补充分析
- 嵌入空间可视化显示结构化特征提供了更好的类别分离（巴黎类别中心距离1.97，伦敦1.84）
- 文本模式分析发现高收益房源普遍强调基础设施（热水器、烘干机、咖啡机等）
- 代价收益分析显示文本特征开发成本高（需NLP预处理），但实际预测价值有限
- 不同城市间存在显著差异：巴黎高收益房源RevPAR阈值高于伦敦，反映市场成熟度差异

### Git应用

![project](imgs/project.jpg)

<div align="center">
    <b>图 17：Project View</b>
</div>

![issue使用总体列表](imgs/issue使用总体列表.jpg)

<div align="center">
    <b>图 18：Issues 使用总体列表</b>
</div>

![issue使用详细图](imgs/issue使用详细图.jpg)

<div align="center">
    <b>图 19：Issues 使用详细图</b>
</div>