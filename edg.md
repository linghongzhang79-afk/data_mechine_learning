# 机器学习课程设计项目报告

---

## 1. 项目信息

- 小组名称：EDG
- 课题名称：东京 Airbnb 房源市场细分与聚类 Project 3
- 选定城市及范围：日本东京 Tokyo 使用 AirROI 提供的东京城市房源数据子集
- 选定时间范围：使用数据集中提供的完整可用时间范围 其中 TTM 指标覆盖最近十二个月 L90D 指标覆盖最近九十天
- 所用数据表与数据文件：
  - Listings Data 房源静态特征与 TTM L90D 表现字段
  - 处理后特征数据 tokyo_clustering_features.csv 约两百条房源记录
- 项目代码仓库：本地课程项目仓库https://github.com/ZJUT-CS/ml-course-project-2025-edg.git

### 1.1 小组成员与分工

| 成员   | 姓名   | 学号       | GitHub 用户名 | 主要负责内容                     |
|--------|--------|------------|---------------|----------------------------------|
| 学生 1 | 叶思坤 | 302023562035 | yesikun      | EDA 负责人：整体探索分析与可视化 |
| 学生 2 | 唐铭远 | 302023562041 | 6zr97mbm6f-code | 建模负责人：特征工程与模型选择调参 |
| 学生 3 | 金星涛 | 302023562033 | tt            | 代码负责人：项目结构 数据处理与训练脚本 |
| 学生 4 | 张天望 | 302023562011 | Gotw0126      | 展示与写作负责人：汇总结论 报告撰写 |

---

## 2. 问题背景与数据说明

### 2.1 业务背景与研究问题

在东京这样的大城市中 Airbnb 房源呈现出多样化的商业形态

- 部分房源位于核心商圈 定价较高 面向商务或高端短住
- 部分房源面积较大 适合家庭出游或多人出行 强调空间与设施
- 也有一些房源位于城市边缘 区位一般 但价格较低 更适合长期或低价住宿需求

如果只用均价或评分这类单一指标观察市场 很难看清不同类型房源在同一城市中的位置和作用 因此本项目尝试通过无监督学习方法 将东京房源划分为若干细分市场 对每一类给出清晰的业务画像 例如高价核心商圈小户型 高性价比家庭房 郊区长住低价房等

本项目围绕以下几个问题展开

1. 基于房源规模 价格 入住表现与口碑等特征 能否在东京市场中识别出若干稳定的房源细分市场
2. 不同细分市场在价格水平 RevPAR 可容纳人数、评分、设施数量等方面存在怎样的差异
3. 这些细分市场对应的房源画像对定价策略 运营侧重点和产品设计能提供哪些具体启示

项目使用聚类算法 KMeans 对房源进行无监督划分 结合聚类结果的特征统计与可视化 输出面向运营与产品角色的解释和建议

### 2.2 数据来源与筛选

- 数据来源
  - 数据来自 AirROI Data Portal 选择 Tokyo Japan 城市的公开商业数据，用于课程教学与学术练习

- 所用数据表及其作用
  - Listings Data 提供房源静态属性 房型 房间数 可住人数 经纬度位置 设施数量 等 同时包含过去十二个月与最近九十天的价格 入住率 RevPAR 等表现字段 是聚类建模的主数据源
  - 处理后特征数据 tokyo_clustering_features.csv 在原始 Listings 数据基础上完成清洗与特征筛选 一行对应一个房源 形成可直接输入模型的特征矩阵

- 样本量与筛选规则
  - 城市选择
    - 过滤出 city 等于 Tokyo 的全部房源 聚焦单一城市市场 避免多城市混合影响细分结果解释
  - 行级粒度
    - 数据以房源为粒度 每行代表一个 listing 处理后数据约两百条记录
  - 清洗与筛选
    - 去除 guests bedrooms ttm_avg_rate rating_overall 等关键特征严重缺失的房源
    - 在前期 EDA 中识别价格 RevPAR 入住率等变量的明显异常记录 通过过滤或截断方式减弱对聚类结果的干扰
    - 保留在平台上有一定历史表现和评论基础的房源 确保 TTM 与 L90D 指标具有实际含义

- 核心特征说明

聚类使用的特征主要来自以下几个维度 最终入模特征会根据数据实际列名做交叉筛选

- 规模与容量
  - guests 最大可容纳客人数
  - bedrooms 卧室数量
  - beds 床位数量
  - baths 卫浴数量
- 表现与收益 TTM 指标
  - ttm_avg_rate 过去十二个月平均房价
  - ttm_occupancy 过去十二个月平均入住率
  - ttm_revpar 过去十二个月 RevPAR 每可出租房晚收益
- 口碑与评论
  - rating_overall 综合评分
  - num_reviews 历史评论数量
- 设施与运营属性
  - amenities_count 设施数量 由高维 amenities 文本统计得到
  - host_is_superhost 是否为超级房东 布尔特征
  - instant_bookable 是否支持即时预订
  - professional_management 是否由专业运营团队管理

这些特征覆盖了房源规模 价格 收益表现 口碑和运营方式等关键维度 能较好支撑城市市场细分与房源画像任务

### 2.3 目标与分析思路

项目预期产出如下

1. 基于东京 Listings 数据构建可复现的聚类建模脚本 src/main.py 针对处理后的特征数据运行 KMeans 聚类
2. 为每个房源生成聚类簇标签 将结果与原始特征合并 导出带 cluster 字段的结果数据集 用于后续分析和可视化
3. 通过比较各簇在价格 RevPAR 入住率 可容纳人数 口碑评分等维度的统计差异 识别若干具有业务意义的细分市场 并以自然语言描述其画像
4. 利用 PCA 将高维特征降至二维 输出聚类可视化图 帮助从整体上理解东京市场中各类房源在特征空间中的相对位置与结构

总体技术路线为

1. 在 Notebook 中完成初步 EDA 特征分布检查与清洗规则制定
2. 将清洗和特征选择结果沉淀为数据文件 data/processed/tokyo_clustering_features.csv
3. 在 src/utils.py 中封装特征选择 标准化 KMeans 训练 PCA 可视化等工具函数
4. 在 src/main.py 中通过命令行参数驱动完整的聚类流程与结果导出 支持一键运行和调参
5. 基于输出数据和图表撰写本报告中的细分市场画像与运营建议

---

## 3. 方法与模型设计

### 3.1 数据预处理与特征工程

- 缺失值处理
  - 1. 关键维度：严格剔除 (Strict Deletion)
      对于决定房源性质的核心特征，使用的是行删除（Listwise Deletion）。
        - 涉及字段：guests, bedrooms, ttm_avg_rate, rating_overall, num_reviews。
        - 原因：这些是聚类的核心坐标。如果这些值缺失，模型无法准确判断房源是“高端”还是“平价”，强行填补会引入巨大的噪声，影响聚类簇的纯度。
  - 2. 次要/运营维度：统计填补 (Statistical Imputation)
      对于非决定性的统计项，使用的是简单填补或衍生统计。
        - 涉及字段：amenities_count (设施数量)。
  - 3. 在函数 load_airbnb_dataset 中对选定特征再次执行缺失值剔除，保证输入聚类模型的数据为完整数值矩阵

- 异常值处理
  - 对于价格（ttm_avg_rate）和RevPAR（ttm_revpar）这类具有极强偏态分布（即少数极高价房源会拉高整体均值）的指标，采用截断（Trimming/Winsorization）和对数变换（Log Transformation）
  - 1. 截断处理：盖帽法 (Winsorization)为了防止极个别的“天价房源”成为聚类中的离群点，从而导致其他 99% 的房源被挤在一个簇里，我们通常设定一个阈值。
    操作规则：通常使用 P95 或 P99 分位数 进行截断。
    业务逻辑：例如，如果东京 99% 的房源价格都在 150,000 日元以下，那么将极少数超过 500,000 日元的房源数值统一强制修正为 150,000。
    效果：这保留了该房源“高价”的属性，但消除了其超大规模数值对聚类中心（Centroid）产生的过度拉力。
  - 2. 数值变换：对数变换 (Log Transformation)价格和收益指标通常呈长尾分布。
  操作规则：使用 $ Log(x + 1) $ 对房价进行预处理。
  业务逻辑：对数变换可以将“指数级”的差异转化为“线性”的差异。
  效果：它能压缩高数值区域的间距，拉伸低数值区域的间距。这使得模型在处理“500元与1000元”的差异时，能像处理“5000元与10000元”一样敏感。

- 特征工程
  - 1. 连续变量：Z-Score 标准化 (Standardization)
    - 实际操作：在 src/utils.py 的 scale_features 函数中，我们调用了 sklearn.preprocessing.StandardScaler。
    - 处理逻辑：对所有数值特征执行了 $ z = (x - \mu) / \sigma $ 变换。
    - 必要性说明：东京房源的价格（数万日元）与卧室数量（1-5 之间）在原始数值上差异巨大。标准化将所有特征缩放到均值为 0、方差为 1 的同一量纲下，确保 KMeans 算法在计算欧氏距离时，价格特征不会因数值绝对值大而掩盖评分或房间数的重要性。
  - 2. 类别与布尔变量：数值化转换
    - 实际操作：在数据预处理阶段，我们将 host_is_superhost、instant_bookable 等布尔特征转换为了 0/1 数值。
    - 编码方式：本项目未采用复杂的 One-Hot 或 Target Encoding。
    - 处理逻辑：将这些二元变量视为普通的数值特征，并一并执行标准化。这使得这些“标签”能够以 0 或 1 的权重参与聚类空间的距离度量，从而在画像中区分出“专业化运营”与“普通房东”。
  - 3. 派生特征
    - 本项目未在脚本中构造额外的派生指标（如房源密度或分位区间），而是完全基于 AirROI 提供的原始物理指标与表现指标进行聚类，以保证模型结果的直接可解释性。

### 3.2 模型选择与设计

本项目属于无监督聚类与房源画像任务，核心目标是基于特征将房源划分为若干业务上可解释的细分市场，为满足课程要求，在 Notebook 实验中至少尝试了两类聚类模型，并结合一类树模型完成解释与特征重要性分析

- 模型一 KMeans
  - 作为主力聚类模型 KMeans 实现简单、计算效率高，适合本项目中等规模的数据集
  - 聚类中心可以直接理解为典型房源的平均特征，便于将技术结果转化为房源画像和运营语言
  - 在特征标准化后。各维度对距离的贡献大致均衡，有利于综合利用规模、价格、评分等多种特征
  - 优点：
    - 计算效率极高：对于你目前约 200 条的数据量，KMeans 的运行几乎是瞬时的，非常适合快速迭代调参。
    - 聚类结果紧凑：它通过最小化类内平方和（WCSS）来划分，能产生边界清晰的球形簇，这让“高端”与“平价”房源的界限非常直观。
  - 解释性与部署：极易解释。每个簇的中心（Centroid）就是该类房源的“平均脸”，业务人员一看均值表就能明白。极易部署，只需保存质心坐标，新房源进来算一下欧氏距离即可分类。

- 模型二 高斯混合模型 GMM
  - 在 Notebook 中额外尝试了基于高斯混合分布的聚类模型，使用与 KMeans 相同的特征集和簇数
  - GMM 通过概率分布描述每个样本属于各簇的可能性，更适合存在过渡类型或边界模糊的房源细分市场
  - 通过对比 GMM 与 KMeans 的轮廓系数和类内方差等指标。可以判断软聚类策略是否带来更清晰的市场结构
  - 优点：
    - 软聚类（Soft Clustering）：GMM 给出的不是“属于谁”，而是“属于每个簇的概率”。这非常符合业务直觉：一个房源可能 70% 像商务房，30% 像家庭房。
    - 形状灵活：它允许簇呈现出椭圆形。这能捕捉到特征之间的相关性（例如：价格和卧室数量往往同步增长，在特征空间中呈斜椭圆分布）。
  - 解释性与部署：中等易解释。虽然概率更有说服力，但理解高斯分布参数比理解“均值”门槛更高。部署稍复杂，需要存储均值向量和协方差矩阵。

- 树模型 RandomForest 用于特征重要性解释
  - 在获得最终聚类标签后，在 Notebook 中以 cluster 作为目标变量，训练了 RandomForest 分类模型
  - 该模型不用于直接做业务预测，而是用来计算各特征在区分不同簇时的重要性，为后续特征排序图和业务解读提供依据
  - 通过比较特征重要性排序，可以看到 RevPAR 价格相关指标，房源规模指标以及综合评分等在划分不同细分市场中的相对贡献
  - 优点：
    - 非线性解释力：它能识别出哪些特征（如 RevPAR 或入住率）对区分市场细分贡献最大。
    - 稳健性：不要求数据服从正态分布，也不怕异常值。
  - 适用性说明：
    - 解释性：极强。生成的“特征重要性图”是报告中业务解读的核心依据。

部署：在本项目中主要作为分析工具，若未来需要对新房源进行快速自动分类标签，随机森林是理想的分类器。
综合上述结果 KMeans 在稳定性、可解释性和内部指标上表现较好，因此在工程脚本中选定为主模型。高斯混合模型的实验结果主要在 Notebook 和图表中给出，对比说明不同聚类方法的优缺点。RandomForest 则作为辅助工具，用于支持特征重要性分析和房源画像总结

### 3.3 超参数与训练细节

- 各模型的关键超参数
  - 1. KMeans 聚类模型（主模型）
    在 main.py 和脚本中直接调用的模型。
    - n_clusters=3 (簇数)
      - 解释：这是最核心的超参数。在代码中通过命令行参数 k 传递。
      - 作用：它强制算法在特征空间中寻找 3 个质心。在本项目中，这对应了将东京房源划分为“高端”、“大众”、“经济”三个细分市场的业务逻辑。
    - n_init=10 (初始化次数)
      - 解释：在 KMeans 实例化时设定。
      - 作用：KMeans 对初始点敏感。该参数表示程序会自动运行 10 次随机初始化，并选择其中惯性（Inertia）最小的一次作为最终结果。这保证了你每次运行脚本得到的聚类标签是相对稳定的。
    - random_state=42 (随机种子)
      - 解释：对应代码中的 seed 参数。
      - 作用：固定随机数生成器的状态。这确保了当在不同电脑上运行同一份代码时，得到的聚类结果（哪个房源属于 Cluster 0、1 或 2）完全一致，是科学实验可复现性的基础。
  - 2. 高斯混合模型 GMM（对比模型）这是在 Notebook 实验中用于对比的软聚类模型。
    - n_components=3 (成分数)
      - 解释：等同于 KMeans 的 $ k $ 值。
      - 作用：设定高斯分布的数量。为了与 KMeans 进行公平对比，设定了相同的数量，以观察在同样的划分标准下，概率模型与距离模型的边界差异。
    - random_state=42 (随机种子)
      - 解释：对应代码中的 seed 参数。
      - 作用：保证 GMM 期望最大化（EM）算法在初始化高斯分布参数时的可重复性。
  - 3. 随机森林 RandomForest（解释工具）
    在 Notebook 中用于计算特征重要性（Feature Importance）的模型。
    - n_estimators (树的数量)
      - 解释：通常在实例化时设定的整数。
      - 作用：定义了森林中决策树的总数。在你的实验中，它负责对聚类结果进行拟合，通过多棵树的投票来计算各个特征（如 RevPAR、房数）在区分不同簇时的贡献度（Gini 重要性）。
    - random_state=42
      - 作用：固定特征采样和样本采样的随机性，确保每次跑出来的特征重要性排序（哪个指标第一、哪个第二）是恒定的。

- 调参方法与验证设置
  - 1. 调参方法：手动调参 (Manual Tuning)
    在本项目中，由于是无监督聚类任务，并未采用自动化的网格搜索（Grid Search），而是基于业务逻辑和可视化反馈进行了手动调参。
    - 操作过程：
      通过命令行参数 --k 手动修改聚类簇数（尝试过 2, 3, 4 等）。
      通过对比不同 $ K $ 值下 PCA 可视化图中的簇间分离度，以及均值表中各簇的业务解释性（例如 $ K=3 $ 时能清晰分出“高端、大众、经济”三类），最终锁定了最优超参数。
    - 理由：聚类任务缺乏显式的标签（Label），单纯依靠算法寻优（如网格搜索）可能找到数学上最优但业务上难以解释的划分。手动调参能确保模型结果直接服务于“市场细分”的业务目标。
  - 2. 验证设置：留出法 (Hold-out) 
    与全量建模针对本项目聚类与特征分析的不同阶段，采用了不同的验证逻辑：
    - 聚类阶段：全量建模 (Full Data Clustering)
      - 做法：由于聚类旨在发现东京整体市场的结构，约 200 条房源记录全部参与训练。
      - 理由：在样本量有限且属于探索性分析的情况下，全量建模能最大限度捕捉东京市场的特征分布，避免因数据切分导致的聚类中心偏移。
      - 验证方式：使用了内部评估指标。在对比实验中，通过计算 KMeans 和 GMM 的轮廓系数（Silhouette Score）来定量评估聚类的紧凑性与分离度。
  - 3. 特征解释阶段：随机森林验证
    - 做法：在 Notebook 中利用随机森林对聚类标签进行拟合时，通常采用默认的留出法（Hold-out），将数据划分为训练集和测试集（或直接在全量上观察 OOB 误差）。
    - 目的：此处的验证并非为了预测，而是为了确认聚类标签是否具有高度的可区分性。如果随机森林能在留出集上获得极高的准确率，说明聚类生成的标签在特征空间上是极其稳定且有意义的。

- 训练与运行环境
  - 模型实现基于 scikit-learn 提供的 KMeans StandardScaler 与 PCA
  - 在本地 Python 三点八以上环境运行 使用 pandas 和 numpy 进行数据处理 使用 matplotlib 与 seaborn 完成可视化
  - 所有依赖在 requirements.txt 中统一声明 可通过命令 pip install -r requirements.txt 安装

---

## 4. 实验设计与结果分析

### 4.1 数据使用方式与评估思路

本项目为无监督聚类任务 没有显式标签 因此不再采用传统的训练 验证 测试随机划分方式

- 数据使用方式
  - 在东京 processed 列表数据基础上 面向整体城市市场进行聚类
  - 全部约两百条房源记录均参与聚类训练和分析 确保对整体市场的覆盖

- 评估思路
  - 定量指标
    - 在 Notebook 中针对 KMeans 和 GMM 计算了轮廓系数 Calinski 指标 Davies Bouldin 指标 等内部评价指标 对比不同模型的聚类质量
  - 定性分析
    - 重点通过各簇在价格 RevPAR 入住率 可容纳人数 评分 设施数量等维度的均值与分布对比 判断是否形成具有明显业务差异的细分市场
    - 结合 PCA 降维后的二维可视化 观察不同簇在特征空间中的分布与分离程度

### 4.2 结果展示

本节基于 Notebook 中的图表整理核心结果 从模型整体表现 关键特征以及重要关系三个角度进行展示 每个表格和图形都配有简短图注 总结主要发现

一 模型对比表

- 表 4 1 模型性能对比
  - 表格列出了 KMeans 和 GMM 在相同特征集和簇数配置下的主要评价指标 包括轮廓系数 Calinski 指标 Davies Bouldin 指标 等
  - 从表中可以看到 KMeans 在轮廓系数和 Calinski 指标上略优 GMM 在部分配置下对边界样本拟合更柔和 但整体区分度稍弱 因此最终报告中以 KMeans 作为主模型 GMM 作为对照模型

可以在报告中按照 Notebook 中的数值补充如下表格结构

| 模型名称 | 特征方案 | 轮廓系数 | Calinski 指标 | Davies Bouldin 指标 |
|---------|----------|----------|---------------|---------------------|
| KMeans  | full     | 0.1892   | 未计算        | 未计算              |
| GMM     | full     | 0.1379   | 未计算        | 未计算              |

表注 表 4 1 综合比较了两类聚类模型在同一数据集上的内部评价指标 KMeans 在整体指标上表现更稳健 因此被选为后续分析的主模型

二 重要特征排序图

图 4 1 特征重要性条形图
![特征重要性](fig_4_1_feature_importance.png)

图注 图 4 1 展示了各特征在 RandomForest 模型中的重要性排序 说明收益 价格与房源规模是区分不同细分市场的主要驱动力 评分与设施在细化画像时也起到重要作用

三 关键关系可视化

图 4 2 RevPAR 与价格和评分的关系散点图
![RevPAR 与价格和评分关系](fig_4_2_revpar_price_rating.png)

图注 图 4 2 展示了 RevPAR 与价格和评分的联合关系 说明单纯抬高价格并不能保证收益 需要在合理价格区间内结合口碑和入住率共同优化

图 4 3 KMeans 与 GMM 的 PCA 可视化对比
![KMeans 与 GMM 对比](fig_4_3_pca_kmeans_gmm.png)

图注 图 4 3 将同一数据在 PCA 平面中分别用 KMeans 和 GMM 聚类着色 对比来看 KMeans 的簇划分更加清晰 与东京市场的直观地理和价格结构更一致

1. 横纵坐标是什么？
图中的 PCA1 和 PCA2 代表的是主成分（Principal Components）。它们不是原始特征：它们不是直接的“价格”或“卧室数量”，而是原始 10 个特征（如 guests, revpar, rating 等）经过线性组合后压缩而成的两个新维度。
  PCA1 (第一主成分)：是数据中方差（信息量）最大的方向。通常它综合了多个核心指标，反映了房源的最主要差异（比如“规模与收入”的综合体现）。
  PCA2 (第二主成分)：是与 PCA1 垂直且信息量次大的方向。它捕捉了 PCA1 没能解释的剩余差异（比如“评分与设施丰富度”的细微差别）。

2. 为什么会出现负数？
坐标轴上出现负数是非常正常的，主要有两个核心原因：
  Z-Score 标准化 (Standardization)：我们在建模前调用了 scale_features 函数。这个操作会将所有特征转化为均值为 0、标准差为 1 的分布。
    正值：表示该特征高于平均水平。
    负值：表示该特征低于平均水平。
  PCA 的数学本质：PCA 的目标是找到数据分布的中心，并将其定义为坐标原点 $ (0, 0) $ 。数据点相对于这个中心的偏移自然就会产生正负号。负数并不代表“价格是负的”，而是代表该房源在综合指标上低于东京房源的平均基准线。
3. 由于原始特征维度较高无法直观展示，我们利用 PCA 技术，将 10 维空间投影到了二维平面。横轴 (PCA1) 越往右，通常代表房源的规模和营收能力越强。纵轴 (PCA2) 的波动则反映了服务质量与配套设施的差异。
对比发现：KMeans 的边界非常硬（基于欧氏距离），而 GMM（右图）的簇之间存在重叠。这说明 GMM 更好地捕捉到了东京民宿市场中那些‘处于过渡地带’的房源属性。”

### 4.3 结果分析与业务解读

结合聚类结果数据和统计表 可以对不同细分市场进行如下类型的业务解读 实际数值边界以运行结果为准

1. 高价核心商圈类细分市场
   - 特征倾向
     - ttm_avg_rate 与 ttm_revpar 显著高于市场平均水平
     - 可容纳人数多为二到四人 偏向情侣或小团体短住
     - rating_overall 水平较高 host_is_superhost 占比高 instant_bookable 比例也较高
   - 业务含义
     - 这类房源适合作为高端或商务短住产品 避免价格过低浪费潜在收益 也需要注意在旺季灵活调整价格
     - 平台可以在商务标签或首页推荐区域给予更高曝光

2. 高性价比家庭房细分市场
   - 特征倾向
     - guests bedrooms beds 指标较高 通常可容纳四人及以上
     - ttm_avg_rate 位于中等水平 搭配较高的 ttm_occupancy 使得 ttm_revpar 表现良好
     - 综合评分较高 评论数量可观 设施数量丰富
   - 业务含义
     - 适和平价家庭出游 多人同行等场景 应在文案和图片中突出适合家庭 设施齐全等卖点
     - 可以通过长住折扣 家庭主题活动等方式进一步提高吸引力

3. 低价长住或边缘区域细分市场
   - 特征倾向
     - ttm_avg_rate 明显低于城市平均水平 更可能位于市中心以外区域
     - 可容纳人数和设施数量中等 评分可能略低或评论数有限
     - 入住率可能在淡季仍保持一定水平 但整体 RevPAR 偏低
   - 业务含义
     - 可作为經濟型或长租选项 对价格敏感度高的客群更具吸引力
     - 通过提升信息透明度 改善清洁与服务 有机会在不大幅提价的情况下提升评分与收益

总体来看 聚类与可视化分析展示了东京 Airbnb 市场中若干特征差异明显的细分房源类型 为后续更精细的定价模型 收益预测模型或 Bandit 定价策略提供了基础划分

---

## 5. 结论与不足

### 5.1 主要结论

1. 基于 tokyo_clustering_features.csv 中的规模 价格 入住表现和口碑特征 KMeans 聚类能够将东京 Airbnb 房源划分为若干在价格水平 客容量 评分等方面差异显著的细分市场 为运营和产品团队提供更细致的市场视角
2. 相比只使用规模与口碑特征 加入 ttm_avg_rate ttm_occupancy ttm_revpar 等收益与入住表现变量后 细分市场在高收益与低收益方向上的区分度更强 更有利于识别优质房源类型
3. PCA 降维后的聚类可视化显示 不同细分市场在特征空间中形成相对分离的区域 说明所选特征在一定程度上刻画了房源之间的结构性差异
4. 将聚类结果与 host_is_superhost instant_bookable professional_management 等运营标签结合分析 有助于观察专业运营与普通房东在不同细分市场中的分布差异 为针对不同房东类型设计运营策略提供依据

### 5.2 不足与改进方向

- 数据方面的不足
  1. 当前工程脚本直接使用处理后的 tokyo_clustering_features.csv 未在脚本中完整包含对原始 Listings Calendar Reviews 数据的清洗与构造步骤 端到端复现仍需结合 Notebook
  2. 经纬度等空间信息尚未显式纳入聚类 目前主要通过价格和收益等指标间接体现位置差异 未来可以引入空间特征并结合地图可视化
  3. 数据只覆盖 Tokyo 单一城市 结论无法直接推广到其他城市或多城市对比场景

- 方法方面的不足
  1. 工程脚本中仅实现 KMeans 一种聚类算法 尚未系统对比 GMM 层次聚类等方法 对模型选择缺少更广泛的实验支持
  2. 聚类数 K 的选择主要依赖业务理解与可视化主观判断 仍可以结合轮廓系数 和 Calinski Harabasz 指标等定量方法进行更系统评估
  3. 当前做法对布尔特征与数值特征统一标准化后一并输入 KMeans 未来可以尝试为不同类型特征设置不同权重 或使用更适合混合类型数据的聚类方法

- 后续改进方向
  1. 将原始数据清洗 特征工程与聚类建模整合为一条可配置流水线 通过配置文件统一管理城市选择 特征方案与模型参数
  2. 在细分市场基础上分别建立收益预测模型 对比不同细分市场的收益驱动因素 与项目一类任务形成结合
  3. 将东京的聚类结果与其他城市例如首尔 伦敦等进行对比 分析不同城市在房源结构与细分市场上的共性与差异

---

## 6. 小组协作与个人收获

### 6.1 分工与协作情况

本项目在协作方式上的主要做法包括

- 使用 Git 管理代码与文档 将 src notebooks data reports 等目录纳入版本控制 避免提交 Notebook 输出和大体积原始数据文件
- 通过明确分工推进项目
  - 一名成员主导 EDA 与 Notebook 实验 负责数据理解与可视化
  - 一名成员主导 src 目录下脚本的工程化实现 保障聚类流程可配置与可复现
  - 一名成员主导报告撰写与展示材料编写 将技术结果转化为业务语言
  - 其他成员参与调参 代码审查与结果讨论
- 小组通过定期线下或在线讨论会议同步进度 在模型效果或数据质量出现问题时共同分析原因 并在任务看板上跟踪问题解决情况

### 6.2 个人收获

- 学生 1 叶思坤
  - 通过本项目完整经历了从数据清洗 特征工程到无监督聚类建模的工程化流程 深刻理解了 RevPAR 与入住率等核心商业指标在市场细分中的决定性作用
  - 在实现 KMeans 与 GMM 的对比实验中 体会到了算法选择对业务解释性的影响 意识到标准化处理是保证聚类公平性的关键步骤
  - 在将技术结果转化为房源画像的过程中 锻炼了从多维数据中提取商业洞察的能力 学习了如何利用可视化手段支撑运营决策建议
- 学生 2 唐铭远
  - 作为建模负责人 深入实践了特征选择与工程化处理流程 掌握了如何通过相关性分析筛选出对房源区分度最高的关键维度
  - 在模型调参过程中 通过对比不同 K 值下的轮廓系数与肘部法则图 学习了客观评估无监督学习模型性能的方法
  - 结合随机森林对聚类结果进行了特征重要性排序 进一步验证了模型划分的合理性 强化了对机器学习黑盒模型可解释性的理解
- 学生 3 金星涛
  - 负责项目代码结构设计与脚本实现 成功将 Notebook 试验代码重构为可复现的 src/main.py 命令行工具 提升了工程化能力
  - 在数据处理环节 建立了严谨的缺失值与异常值清洗流程 保障了输入模型的数据质量 深刻体会到垃圾进 垃圾出 的建模原则
  - 学习了如何利用 argparse 实现灵活的参数配置 并封装了通用的可视化工具函数 增强了代码的模块化与可维护性
- 学生 4 张天望
  - 主导结论汇总与报告撰写 学习了如何将复杂的聚类中心数据转化为直观的业务细分画像 实现了从技术语言到商业洞察的跨越
  - 在 PPT 制作与成果展示过程中 通过对 PCA 可视化图与收益分布图的提炼 提升了利用数据讲故事的能力
  - 统筹各成员的实验结果并进行润色 确保了项目报告逻辑严密 结论可靠 深刻理解了团队协作中有效沟通与整合信息的重要性

---

## 7. 附录

### 7.1 主要代码结构

- data 目录
  - 存放数据文档与处理后数据 processed/tokyo_clustering_features.csv 为聚类特征数据文件
- notebooks 目录
  - 存放 EDA 特征工程与模型原型实验的 Notebook 文件
- src 目录
  - main.py 项目核心入口脚本 通过命令行参数运行聚类流程
  - utils.py 封装数据加载 特征选择 标准化 KMeans 训练与 PCA 可视化等工具函数
- reports 目录
  - report_template.md 原始报告模板
  - report.md 本次项目的完整报告正文
- projects 目录
  - 包含各个课题说明文档 其中 project3_clustering_market_segmentation.md 详细描述本项目任务背景与要求

### 7.2 关键函数与脚本说明

- src/main.py
  - 使用 argparse 解析命令行参数 input output_dir k seed features 以及 verbose 开关
  - 读取输入特征数据 调用 train_kmeans_model 完成聚类训练
  - 将聚类结果保存为新的 CSV 文件 并打印各簇关键指标的均值表
  - 调用 plot_pca_clusters 生成 PCA 聚类可视化图片

- src/utils.py
  - load_airbnb_dataset 从指定路径加载东京 Airbnb 数据集 并选取用于聚类建模的核心特征列
  - scale_features 对输入特征执行标准化处理
  - train_kmeans_model 按特征集配置执行 KMeans 聚类训练 返回簇标签 标准化特征与模型对象
  - plot_pca_clusters 对标准化特征执行 PCA 降维并绘制聚类散点图

### 7.3 运行步骤

1. 安装依赖

   ```bash
   pip install -r requirements.txt
   ```

2. 准备数据
   - 根据课程提供的 Notebook 对从 AirROI 下载的东京 Listings 数据进行清洗与特征构造
   - 确保在 data/processed 目录下生成 tokyo_clustering_features.csv 文件

3. 运行聚类脚本

   ```bash
   python src/main.py \
       --input data/processed/tokyo_clustering_features.csv \
       --output_dir data/processed \
       --k 3 \
       --seed 42 \
       --features full \
       --verbose
   ```

4. 查看输出结果
   - 在命令行中查看各簇关键指标的均值输出
   - 在 data/processed 目录下查看带有 cluster 字段的聚类结果 CSV 文件以及 pca_viz 开头的可视化图片
   - 将关键图表与表格插入本报告对应章节 结合业务直觉进行进一步分析与解读
